{
 "metadata": {
  "name": "",
  "signature": "sha256:0fb4a55e9fe88850815a6129d7cdbb5500bec34170f6554b64fda90dbe2a2ca9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import random\n",
      "from os import path\n",
      "import string\n",
      "\n",
      "import nltk\n",
      "\n",
      "from nltk.corpus import brown\n",
      "from nltk.corpus import nps_chat  #nps chat\n",
      "\n",
      "import testing_util as util\n",
      "import term_scoring\n",
      "from testing_util import sample_sets, final_sets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** 1. Word Searching. **\n",
      "- Improve the list of words by identifying or adding more prominent words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class WordSearcher(object):\n",
      "    def __init__(self, wordlist=None, key=\"\", name=\"wordsearcher\"):\n",
      "        self.wordlist = wordlist if wordlist else []\n",
      "        self.key = key\n",
      "        self.name=name\n",
      "    \n",
      "    def add(self, wordlist):\n",
      "        self.wordlist.extend(wordlist)\n",
      "    \n",
      "    def clear(self):\n",
      "        self.wordlist = []\n",
      "    \n",
      "    def __call__(self, text):\n",
      "        out = {}\n",
      "        for word in self.wordlist:\n",
      "            out[\"{}has({})\".format(self.key, word)] = 1 if re.search(word, text, re.IGNORECASE) else 0\n",
      "        return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worder = WordSearcher()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worder.clear()\n",
      "#1-business\n",
      "worder.add([\"money\", \"credit\", \"business\", \"sell\"])\n",
      "#2-computers\n",
      "worder.add([\"comp\", \"linux\", \"windows\", \"internet\",\n",
      "            \"software\", \"program\", r\"\\d+(mb|kb|gb)\",\n",
      "            \"download\", \"e-?mail\", \"web\", \"laptop\",\n",
      "            \"wireless\", \"website\", \"html\", \"smtp\"])\n",
      "#3 - entertainment\n",
      "worder.add([\"song\", \"movie\", \"music\", \"favorite\",\n",
      "            \"show\", \"first\", \"rock\", \"magazine\",\n",
      "            \"lyric\", \"series\", \"episode\", \"singer\",\n",
      "            \"act(or|ress)\", \"cartoon\", \"riddle\", \"joke\"\n",
      "            \"album\"])\n",
      "#4 - family/relationships\n",
      "worder.add([\"love\", \"girl\", \"boy\", \"relationship\",\n",
      "            \"women\", \"date\", \"(boy|girl)friend\", \"marri\",\n",
      "            \"wife\", \"husband\", \"family\", \"dating\", \"sex\",\n",
      "            \" friend\", \"roman(ce|tic)\"\n",
      "            ])\n",
      "#5 - education and reference\n",
      "worder.add([\"school\", \"college\", \"study\", \"english\", \"word\",\n",
      "            \"history\", \"educat\", \"teach\", \"book\", \"spanish\",\n",
      "            \"university\", \"grade\", \"exam\", \"learn\"])\n",
      "#6 - Health\n",
      "worder.add([\"pain\", \"cold\", \"body\", \"surgery\", \"blood\",\n",
      "            \"weight\", \"health\", \"smok(es|ing)\", \"symptoms\",\n",
      "            \"cure\", \"diet\", \"treatment\", \"medic\", \"penis\",\n",
      "            \"vomit\", \"acne\", \"\\d+mg\", \"itching\", \"teeth\",\n",
      "            \"materbat\"])\n",
      "#7 - Science&Mathematics\n",
      "worder.add([\"earth\", \"world\", \"theory\", \"universe\", \"point\",\n",
      "            \"planet\", \"moon\", \"science\", \"math\", \"atom\", \"stars\",\n",
      "            \"\\d+[/*^+-]\\d+\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_propnouns(text):\n",
      "    if re.findall(\"[A-Z]\\w [A-Z]\", text):\n",
      "        return {\"has prop noun\":1}\n",
      "    else:\n",
      "        return {\"has prop noun\":0}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Collocations of Noun Phrases **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Collocator(object):\n",
      "    def __init__(self, name=\"collocator\"):\n",
      "        self.collocations = []\n",
      "        self.name = name\n",
      "\n",
      "    def train(self, samples):\n",
      "        tokens = [w.lower() for s in sample_sets for w in nltk.tokenize.word_tokenize(s[1])]\n",
      "        tokens = [t for t in tokens if (not re.findall(\"[']|what|which|where|have|why|they\", t, re.I)) and len(t)>3]\n",
      "        bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
      "        finder = nltk.collocations.BigramCollocationFinder.from_words(tokens)\n",
      "        finder.apply_freq_filter(5)\n",
      "        self.collocations = finder.nbest(bigram_measures.pmi, 100)\n",
      "    \n",
      "    def __call__(self, text):\n",
      "        for co in self.collocations:\n",
      "            if \"{} {}\".format(co[0], co[1]) in text.lower():\n",
      "                return {\"{}has{}\".format(self.name, co): 1}\n",
      "            else:\n",
      "                return {\"{}has{}\".format(self.name, co): 0}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "colo = Collocator()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Text.Similar Contexts **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
      "text.similar('')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Syntactical Tagging for Noun-Phrases **\n",
      "- Refer to Notebook: Common Objects of Verbs. Thesaurus For Main Topics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load bag of words but retain sentences\n",
      "corpus_sents = \"\"\n",
      "\n",
      "for key, value in sample_sets:\n",
      "    if key == '1':\n",
      "        corpus_sents += value\n",
      "    \n",
      "# Spliting Corpus into sentences\n",
      "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "sents = sent_tokenizer.tokenize(corpus_sents.strip())\n",
      "print sents[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['roth ira vs 401k?', 'what is the difference between roth ira and 401k?', 'when should i prefer one over the other?how many planes fedex has?', 'i heard that it is the largest airline in the worldwhat are some tips on finding a good mortgage broker?', 'what are some tips on finding a good mortgage broker?nice apartment building near sbc park?', 'any recommendations for a nice apartment building in sf generally in the sbc park area?what is the best riddle that you know?', \"i'm trying to have a library of the best riddles that people encountered.\", 'so a good riddle would be a riddle that has no ugly tricks in it- pure logic answer \\xe2\\x80\\x93 no tricks, no funky solutions.economics of running a restaurant?', 'running a restaurant looks like hard work and long hours.', '&#xd;&lt;br&gt;&lt;br&gt;what percentage of restaurants are profitable?']\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a trained tagger using the brown corpus\n",
      "training_data = brown.tagged_sents()\n",
      "\n",
      "def backoff_tagger(train_sents):\n",
      "    t0 = nltk.DefaultTagger('NN')\n",
      "    t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
      "    t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
      "    t3 = nltk.TrigramTagger(train_sents, backoff=t2)\n",
      "    return t3\n",
      "\n",
      "ngram_tagger = backoff_tagger(training_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** To Improve ** \n",
      "- I tried to do regex for URLs but I can't seem to figure that out.\n",
      "- pat_url = re.compile(  r'''\n",
      "                     (?x)((http|ftp|gopher)://(\\w+[:.]?){2,}(/?|[^ \\n\\r\"]+[\\w/])(?=[\\s\\.,>)'\"\\]]))''')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "def verb_tagging(sentence):\n",
      "    \n",
      "    # spliting Corpus into sentences\n",
      "    sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "    sents = sent_tokenizer.tokenize(sentence.strip())\n",
      "    \n",
      "    gerunds = []\n",
      "    pattern = r'''(?x)\n",
      "    ([A-Z]\\.\\s[A-Z]\\.\\s\\w+)\n",
      "    |([A-Z]\\.)\\s([A-Z]\\.)\n",
      "    |([A-Z]\\.)+\n",
      "    |\\w+([-']\\w+)*\n",
      "    |\\$?\\d+(\\.\\d+)?%?\n",
      "    |[.,?;]+\n",
      "    '''\n",
      "    \n",
      "    for sent in sents:\n",
      "\n",
      "        words_list = nltk.regexp_tokenize(sent, pattern)\n",
      "        words = [word for word in words_list if word not in string.punctuation] #filter out unwanted words\n",
      "\n",
      "        sentence_tagged = nltk.pos_tag(words) #find position tagging\n",
      "\n",
      "        verbs = [v[0] for v in sentence_tagged if re.match('V.*', v[1])]\n",
      "\n",
      "        gerunds.extend(verbs)\n",
      "    \n",
      "    return gerunds\n",
      "    \n",
      "\n",
      "#     for word_tuple[1] in sentence:\n",
      "#         if word_tuple[1] == \"V\":\n",
      "#             gerunds.append(word_tuple[1])\n",
      "\n",
      "    \n",
      "#     grammar = r\"\"\"NP: {<DT><JJ><NN>} \n",
      "#                       {<DT><NN>+}\n",
      "#                       {<(JJS|JJR|JJ|NN|NNS)>+ <(NN|NNS|CD|CDS)>}\n",
      "#                       {<(NN|NNS)> <(JJ)>}\"\"\"\n",
      "\n",
      "#     cp = nltk.RegexpParser(grammar)  \n",
      "#     tree = cp.parse(sentence)        \n",
      "\n",
      "#     for subtree in tree.subtrees():\n",
      "#         if subtree.node == 'NP': noun_phrases.append(subtree.leaves.im_self)\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fd_gerunds = nltk.FreqDist(gerunds)\n",
      "fd_gerunds.items()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "[('is', 336),\n",
        " ('do', 209),\n",
        " ('are', 129),\n",
        " ('have', 106),\n",
        " ('i', 87),\n",
        " ('get', 81),\n",
        " ('know', 69),\n",
        " ('be', 64),\n",
        " ('does', 63),\n",
        " ('find', 60),\n",
        " ('want', 53),\n",
        " ('was', 52),\n",
        " ('am', 36),\n",
        " ('has', 33),\n",
        " ('need', 30),\n",
        " ('make', 29),\n",
        " ('buy', 25),\n",
        " ('go', 25),\n",
        " ('did', 23),\n",
        " ('think', 23),\n",
        " ('had', 18),\n",
        " ('looking', 18),\n",
        " ('see', 18),\n",
        " ('going', 17),\n",
        " ('getting', 16),\n",
        " ('like', 16),\n",
        " ('take', 16),\n",
        " ('say', 15),\n",
        " ('help', 14),\n",
        " ('pay', 14),\n",
        " ('were', 13),\n",
        " ('being', 12),\n",
        " ('sell', 12),\n",
        " ('change', 11),\n",
        " ('wondering', 11),\n",
        " ('become', 10),\n",
        " ('been', 10),\n",
        " ('made', 10),\n",
        " ('mean', 10),\n",
        " ('put', 10),\n",
        " ('trying', 10),\n",
        " ('work', 10),\n",
        " ('got', 9),\n",
        " ('look', 9),\n",
        " ('using', 9),\n",
        " ('ask', 8),\n",
        " ('come', 8),\n",
        " ('give', 8),\n",
        " ('start', 8),\n",
        " ('tell', 8),\n",
        " ('answer', 7),\n",
        " ('call', 7),\n",
        " ('called', 7),\n",
        " ('making', 7),\n",
        " ('sending', 7),\n",
        " ('thinking', 7),\n",
        " ('found', 6),\n",
        " ('keep', 6),\n",
        " ('learn', 6),\n",
        " ('left', 6),\n",
        " ('live', 6),\n",
        " ('lost', 6),\n",
        " ('said', 6),\n",
        " ('send', 6),\n",
        " ('united', 6),\n",
        " ('use', 6),\n",
        " ('wanted', 6),\n",
        " ('working', 6),\n",
        " ('xa', 6),\n",
        " ('bring', 5),\n",
        " ('com', 5),\n",
        " ('doing', 5),\n",
        " ('dont', 5),\n",
        " ('etc', 5),\n",
        " ('feel', 5),\n",
        " ('goes', 5),\n",
        " ('having', 5),\n",
        " ('hurt', 5),\n",
        " ('let', 5),\n",
        " ('love', 5),\n",
        " ('open', 5),\n",
        " ('paid', 5),\n",
        " ('please', 5),\n",
        " ('read', 5),\n",
        " ('rent', 5),\n",
        " ('says', 5),\n",
        " ('seem', 5),\n",
        " ('stop', 5),\n",
        " ('wait', 5),\n",
        " (\"what's\", 5),\n",
        " ('worked', 5),\n",
        " ('addicted', 4),\n",
        " ('amp', 4),\n",
        " ('believe', 4),\n",
        " ('create', 4),\n",
        " ('file', 4),\n",
        " ('filed', 4),\n",
        " ('heard', 4),\n",
        " ('knows', 4),\n",
        " ('likes', 4),\n",
        " ('listed', 4),\n",
        " ('makes', 4),\n",
        " ('owe', 4),\n",
        " ('own', 4),\n",
        " ('paying', 4),\n",
        " ('run', 4),\n",
        " ('running', 4),\n",
        " ('santa', 4),\n",
        " ('started', 4),\n",
        " ('stay', 4),\n",
        " ('try', 4),\n",
        " ('u', 4),\n",
        " ('win', 4),\n",
        " ('write', 4),\n",
        " ('add', 3),\n",
        " ('anybody', 3),\n",
        " ('blocked', 3),\n",
        " ('bought', 3),\n",
        " ('built', 3),\n",
        " ('cant', 3),\n",
        " ('choose', 3),\n",
        " ('concentrate', 3),\n",
        " ('delivered', 3),\n",
        " ('die', 3),\n",
        " ('died', 3),\n",
        " ('done', 3),\n",
        " ('everything', 3),\n",
        " ('existing', 3),\n",
        " ('feels', 3),\n",
        " ('fixed', 3),\n",
        " ('hav', 3),\n",
        " ('informed', 3),\n",
        " ('last', 3),\n",
        " ('located', 3),\n",
        " ('mail', 3),\n",
        " ('needed', 3),\n",
        " ('play', 3),\n",
        " ('protect', 3),\n",
        " ('purchase', 3),\n",
        " ('recommend', 3),\n",
        " ('red', 3),\n",
        " ('related', 3),\n",
        " ('s', 3),\n",
        " ('save', 3),\n",
        " ('saw', 3),\n",
        " ('seeking', 3),\n",
        " ('seems', 3),\n",
        " ('sold', 3),\n",
        " ('starting', 3),\n",
        " ('studing', 3),\n",
        " ('t', 3),\n",
        " ('talk', 3),\n",
        " ('told', 3),\n",
        " ('tried', 3),\n",
        " ('understand', 3),\n",
        " ('went', 3),\n",
        " ('added', 2),\n",
        " ('allowed', 2),\n",
        " ('appreciated', 2),\n",
        " ('atracted', 2),\n",
        " ('based', 2),\n",
        " ('beat', 2),\n",
        " ('bed', 2),\n",
        " ('bored', 2),\n",
        " ('buying', 2),\n",
        " ('c', 2),\n",
        " ('california', 2),\n",
        " ('calls', 2),\n",
        " ('came', 2),\n",
        " ('cannot', 2),\n",
        " ('changing', 2),\n",
        " ('chat', 2),\n",
        " ('checking', 2),\n",
        " ('china', 2),\n",
        " ('cold', 2),\n",
        " ('coming', 2),\n",
        " ('commit', 2),\n",
        " ('costs', 2),\n",
        " ('counted', 2),\n",
        " ('cover', 2),\n",
        " ('dated', 2),\n",
        " ('deal', 2),\n",
        " ('decide', 2),\n",
        " ('delete', 2),\n",
        " ('design', 2),\n",
        " ('divorced', 2),\n",
        " (\"don't\", 2),\n",
        " ('download', 2),\n",
        " ('downloaded', 2),\n",
        " ('drink', 2),\n",
        " ('drive', 2),\n",
        " ('each', 2),\n",
        " ('eat', 2),\n",
        " ('edit', 2),\n",
        " ('email', 2),\n",
        " ('eve', 2),\n",
        " ('explain', 2),\n",
        " ('export', 2),\n",
        " ('fast', 2),\n",
        " ('filled', 2),\n",
        " ('forced', 2),\n",
        " ('format', 2),\n",
        " ('fund', 2),\n",
        " ('gambling', 2),\n",
        " ('gets', 2),\n",
        " ('gold', 2),\n",
        " ('gone', 2),\n",
        " ('gtx', 2),\n",
        " ('guys', 2),\n",
        " ('handed', 2),\n",
        " ('happen', 2),\n",
        " ('helping', 2),\n",
        " ('hiring', 2),\n",
        " ('hoping', 2),\n",
        " ('house', 2),\n",
        " (\"i've\", 2),\n",
        " ('id', 2),\n",
        " ('im', 2),\n",
        " ('improve', 2),\n",
        " ('invest', 2),\n",
        " (\"it's\", 2),\n",
        " ('killed', 2),\n",
        " ('kissing', 2),\n",
        " ('knew', 2),\n",
        " ('known', 2),\n",
        " ('listened', 2),\n",
        " ('lived', 2),\n",
        " ('locate', 2),\n",
        " ('maintaining', 2),\n",
        " ('married', 2),\n",
        " ('men', 2),\n",
        " ('ok', 2),\n",
        " ('operated', 2),\n",
        " ('owned', 2),\n",
        " ('paycheck', 2),\n",
        " ('pending', 2),\n",
        " ('pick', 2),\n",
        " ('post', 2),\n",
        " ('pray', 2),\n",
        " ('prepare', 2),\n",
        " ('prove', 2),\n",
        " ('provided', 2),\n",
        " ('putting', 2),\n",
        " ('receive', 2),\n",
        " ('received', 2),\n",
        " ('recieved', 2),\n",
        " ('registered', 2),\n",
        " ('remove', 2),\n",
        " ('report', 2),\n",
        " ('required', 2),\n",
        " ('roll', 2),\n",
        " ('seeing', 2),\n",
        " ('selected', 2),\n",
        " ('selling', 2),\n",
        " ('sent', 2),\n",
        " ('shaped', 2),\n",
        " ('shoes', 2),\n",
        " ('show', 2),\n",
        " ('sit', 2),\n",
        " ('smells', 2),\n",
        " ('someone', 2),\n",
        " ('speak', 2),\n",
        " ('spend', 2),\n",
        " ('squeeze', 2),\n",
        " ('stand', 2),\n",
        " ('startup', 2),\n",
        " ('stated', 2),\n",
        " ('stolen', 2),\n",
        " ('studies', 2),\n",
        " ('supposed', 2),\n",
        " ('teach', 2),\n",
        " ('tells', 2),\n",
        " ('time', 2),\n",
        " ('tip', 2),\n",
        " ('tired', 2),\n",
        " ('transfer', 2),\n",
        " ('tree', 2),\n",
        " ('type', 2),\n",
        " ('used', 2),\n",
        " ('w', 2),\n",
        " ('watch', 2),\n",
        " ('website', 2),\n",
        " ('weigh', 2),\n",
        " ('won', 2),\n",
        " ('worried', 2),\n",
        " ('written', 2),\n",
        " ('xd', 2),\n",
        " ('yawning', 2),\n",
        " ('abstract', 1),\n",
        " ('abyone', 1),\n",
        " ('according', 1),\n",
        " ('accounting', 1),\n",
        " ('accpt', 1),\n",
        " ('achive', 1),\n",
        " ('achives', 1),\n",
        " ('acomplish', 1),\n",
        " ('acting', 1),\n",
        " ('adapted', 1),\n",
        " ('adding', 1),\n",
        " ('adjusting', 1),\n",
        " ('admitting', 1),\n",
        " ('advantaged', 1),\n",
        " ('advertise', 1),\n",
        " ('advertising', 1),\n",
        " ('advise', 1),\n",
        " ('affiliated', 1),\n",
        " ('afford', 1),\n",
        " ('agencis', 1),\n",
        " ('agrees', 1),\n",
        " ('air', 1),\n",
        " ('aired', 1),\n",
        " ('allow', 1),\n",
        " ('allows', 1),\n",
        " ('alot', 1),\n",
        " ('annoint', 1),\n",
        " ('answered', 1),\n",
        " ('any1', 1),\n",
        " ('anyone', 1),\n",
        " ('apologize', 1),\n",
        " ('apple', 1),\n",
        " ('apply', 1),\n",
        " ('appreciate', 1),\n",
        " ('approved', 1),\n",
        " ('arrested', 1),\n",
        " ('asking', 1),\n",
        " ('asks', 1),\n",
        " ('associated', 1),\n",
        " ('asst', 1),\n",
        " ('assume', 1),\n",
        " ('attempted', 1),\n",
        " ('attending', 1),\n",
        " ('avoid', 1),\n",
        " ('balancing', 1),\n",
        " ('banking', 1),\n",
        " ('becoming', 1),\n",
        " ('began', 1),\n",
        " ('believed', 1),\n",
        " ('belongs', 1),\n",
        " ('besides', 1),\n",
        " ('bethlehem', 1),\n",
        " ('blended', 1),\n",
        " ('blog', 1),\n",
        " ('boise', 1),\n",
        " ('borrow', 1),\n",
        " ('borrowing', 1),\n",
        " ('bounce', 1),\n",
        " ('boy', 1),\n",
        " ('brushed', 1),\n",
        " ('build', 1),\n",
        " ('buried', 1),\n",
        " ('bury', 1),\n",
        " ('buuying', 1),\n",
        " ('cancelling', 1),\n",
        " ('care', 1),\n",
        " ('carrie', 1),\n",
        " ('cash', 1),\n",
        " ('cashing', 1),\n",
        " ('cause', 1),\n",
        " ('cave', 1),\n",
        " ('changed', 1),\n",
        " ('charge', 1),\n",
        " ('charging', 1),\n",
        " ('cheap', 1),\n",
        " ('cheapdid', 1),\n",
        " ('cheating', 1),\n",
        " ('check', 1),\n",
        " ('checked', 1),\n",
        " ('chicken', 1),\n",
        " ('child', 1),\n",
        " ('chop', 1),\n",
        " ('chose', 1),\n",
        " ('chuck', 1),\n",
        " ('claim', 1),\n",
        " ('claus', 1),\n",
        " ('clean', 1),\n",
        " ('cleaning', 1),\n",
        " ('clear', 1),\n",
        " ('clearing', 1),\n",
        " ('clothes', 1),\n",
        " ('clue', 1),\n",
        " ('comes', 1),\n",
        " ('companys', 1),\n",
        " ('compare', 1),\n",
        " ('comparing', 1),\n",
        " ('competing', 1),\n",
        " ('compose', 1),\n",
        " ('computer', 1),\n",
        " ('confused', 1),\n",
        " ('confusing', 1),\n",
        " ('considered', 1),\n",
        " ('considering', 1),\n",
        " ('contact', 1),\n",
        " ('continues', 1),\n",
        " ('continuing', 1),\n",
        " ('contributed', 1),\n",
        " ('controled', 1),\n",
        " ('convienent', 1),\n",
        " ('cook', 1),\n",
        " ('cool', 1),\n",
        " ('copyright', 1),\n",
        " ('corporate', 1),\n",
        " ('corrects', 1),\n",
        " ('count', 1),\n",
        " ('countyis', 1),\n",
        " ('covered', 1),\n",
        " ('crashes', 1),\n",
        " ('crazy', 1),\n",
        " ('cream', 1),\n",
        " ('created', 1),\n",
        " ('custom', 1),\n",
        " ('cut', 1),\n",
        " ('cyber', 1),\n",
        " ('dad', 1),\n",
        " ('david', 1),\n",
        " ('deactivated', 1),\n",
        " ('deceased', 1),\n",
        " ('decides', 1),\n",
        " ('deduct', 1),\n",
        " ('deep', 1),\n",
        " ('defined', 1),\n",
        " ('delegent', 1),\n",
        " ('demanding', 1),\n",
        " ('department', 1),\n",
        " ('depending', 1),\n",
        " ('deposite', 1),\n",
        " ('describes', 1),\n",
        " ('destructive', 1),\n",
        " ('details', 1),\n",
        " ('developing', 1),\n",
        " ('didnt', 1),\n",
        " ('dining', 1),\n",
        " ('disagree', 1),\n",
        " ('dividing', 1),\n",
        " ('document', 1),\n",
        " ('documented', 1),\n",
        " ('doesnt', 1),\n",
        " ('dollars', 1),\n",
        " ('donate', 1),\n",
        " ('drained', 1),\n",
        " ('dream', 1),\n",
        " ('dying', 1),\n",
        " ('e', 1),\n",
        " ('educated', 1),\n",
        " ('effective', 1),\n",
        " ('emailed', 1),\n",
        " ('encountered', 1),\n",
        " ('ended', 1),\n",
        " ('ensure', 1),\n",
        " ('entertwined', 1),\n",
        " ('environment', 1),\n",
        " ('episode', 1),\n",
        " ('erase', 1),\n",
        " ('estimating', 1),\n",
        " ('everyone', 1),\n",
        " ('exhauseted', 1),\n",
        " ('expect', 1),\n",
        " ('experience', 1),\n",
        " ('extend', 1),\n",
        " ('extreme', 1),\n",
        " ('failed', 1),\n",
        " ('fallen', 1),\n",
        " ('fault', 1),\n",
        " ('favorite', 1),\n",
        " ('fell', 1),\n",
        " ('fern', 1),\n",
        " ('figured', 1),\n",
        " ('finished', 1),\n",
        " ('flakes', 1),\n",
        " ('flip', 1),\n",
        " ('float', 1),\n",
        " ('flown', 1),\n",
        " ('focused', 1),\n",
        " ('follow', 1),\n",
        " ('following', 1),\n",
        " ('followup', 1),\n",
        " ('forged', 1),\n",
        " ('forgot', 1),\n",
        " ('forgots', 1),\n",
        " ('forgotten', 1),\n",
        " ('fox', 1),\n",
        " ('freestyle', 1),\n",
        " ('frozen', 1),\n",
        " ('fuck', 1),\n",
        " ('fuh-reakin', 1),\n",
        " ('fun', 1),\n",
        " ('gamble', 1),\n",
        " ('gang', 1),\n",
        " ('gate', 1),\n",
        " ('gates', 1),\n",
        " ('gathering', 1),\n",
        " ('gave', 1),\n",
        " ('gay', 1),\n",
        " (\"girlfriend's\", 1),\n",
        " ('gives', 1),\n",
        " ('giving', 1),\n",
        " ('gm', 1),\n",
        " ('good', 1),\n",
        " ('google', 1),\n",
        " ('gotta', 1),\n",
        " ('gov', 1),\n",
        " ('grew', 1),\n",
        " ('grow', 1),\n",
        " ('guess', 1),\n",
        " ('handles', 1),\n",
        " ('happened', 1),\n",
        " ('happenen', 1),\n",
        " ('hated', 1),\n",
        " ('havent', 1),\n",
        " (\"he's\", 1),\n",
        " ('heaven', 1),\n",
        " ('hendrix', 1),\n",
        " ('hi', 1),\n",
        " ('hit', 1),\n",
        " ('hoiw', 1),\n",
        " ('hope', 1),\n",
        " ('hoplessness', 1),\n",
        " ('iceland', 1),\n",
        " ('imagine', 1),\n",
        " ('incarcerated', 1),\n",
        " ('include', 1),\n",
        " ('including', 1),\n",
        " ('income', 1),\n",
        " ('increase', 1),\n",
        " ('india', 1),\n",
        " ('info', 1),\n",
        " ('informaton', 1),\n",
        " ('inhansed', 1),\n",
        " ('install', 1),\n",
        " ('interested', 1),\n",
        " ('intereviewing', 1),\n",
        " ('intruding', 1),\n",
        " ('invented', 1),\n",
        " ('inviting', 1),\n",
        " ('irritating', 1),\n",
        " ('jeff', 1),\n",
        " ('join', 1),\n",
        " ('jump', 1),\n",
        " ('k-2x', 1),\n",
        " ('kept', 1),\n",
        " ('kill', 1),\n",
        " ('kind', 1),\n",
        " ('king', 1),\n",
        " ('kiss', 1),\n",
        " ('lake', 1),\n",
        " ('land', 1),\n",
        " ('lay', 1),\n",
        " ('leasing', 1),\n",
        " ('lefted', 1),\n",
        " ('letting', 1),\n",
        " ('licensed', 1),\n",
        " ('listen', 1),\n",
        " ('living', 1),\n",
        " ('llc', 1),\n",
        " ('locxate', 1),\n",
        " ('login', 1),\n",
        " ('looked', 1),\n",
        " ('loose', 1),\n",
        " ('lose', 1),\n",
        " ('losing', 1),\n",
        " ('loves', 1),\n",
        " ('lowered', 1),\n",
        " ('lt', 1),\n",
        " ('lying', 1),\n",
        " ('m', 1),\n",
        " ('madison', 1),\n",
        " ('males', 1),\n",
        " ('manufacture', 1),\n",
        " ('marks', 1),\n",
        " ('meaning', 1),\n",
        " ('means', 1),\n",
        " ('meant', 1),\n",
        " ('melt', 1),\n",
        " ('messaging', 1),\n",
        " ('messing', 1),\n",
        " ('michael', 1),\n",
        " ('mightymouse', 1),\n",
        " ('miss', 1),\n",
        " ('missing', 1),\n",
        " ('mom', 1),\n",
        " ('motivate', 1),\n",
        " ('move', 1),\n",
        " ('moving', 1),\n",
        " (\"msds's\", 1),\n",
        " ('murple', 1),\n",
        " ('name', 1),\n",
        " ('needing', 1),\n",
        " ('neglected', 1),\n",
        " ('nictitating', 1),\n",
        " ('nieve', 1),\n",
        " ('nintendo', 1),\n",
        " ('nominated', 1),\n",
        " ('noticed', 1),\n",
        " ('obligated', 1),\n",
        " ('obtained', 1),\n",
        " ('oem', 1),\n",
        " ('offer', 1),\n",
        " ('offered', 1),\n",
        " ('offers', 1),\n",
        " ('okay', 1),\n",
        " ('opening', 1),\n",
        " ('ordered', 1),\n",
        " ('originated', 1),\n",
        " ('ottoman', 1),\n",
        " ('outsourcing', 1),\n",
        " ('overcharged', 1),\n",
        " ('overcoming', 1),\n",
        " ('owning', 1),\n",
        " ('owns', 1),\n",
        " ('pain', 1),\n",
        " ('participating', 1),\n",
        " ('perfect', 1),\n",
        " ('personalize', 1),\n",
        " ('picked', 1),\n",
        " ('pictures', 1),\n",
        " ('planned', 1),\n",
        " ('planning', 1),\n",
        " ('plans', 1),\n",
        " ('plated', 1),\n",
        " ('pocketed', 1),\n",
        " ('pockets', 1),\n",
        " ('pop', 1),\n",
        " ('posted', 1),\n",
        " ('potatoes', 1),\n",
        " ('practiced', 1),\n",
        " ('predicted', 1),\n",
        " ('prefer', 1),\n",
        " ('processed', 1),\n",
        " ('produce', 1),\n",
        " ('promoted', 1),\n",
        " ('pronounced', 1),\n",
        " ('provide', 1),\n",
        " ('provides', 1),\n",
        " ('providing', 1),\n",
        " ('publish', 1),\n",
        " ('purchasing', 1),\n",
        " ('pure', 1),\n",
        " ('purple', 1),\n",
        " ('pushing', 1),\n",
        " ('qualify', 1),\n",
        " ('quotes', 1),\n",
        " ('raise', 1),\n",
        " ('raised', 1),\n",
        " ('reach', 1),\n",
        " ('reaches', 1),\n",
        " ('reaching', 1),\n",
        " ('realizes', 1),\n",
        " ('reasonable', 1),\n",
        " ('reasons', 1),\n",
        " ('recconnend', 1),\n",
        " ('receiving', 1),\n",
        " ('recomend', 1),\n",
        " ('recommended', 1),\n",
        " ('recorded', 1),\n",
        " ('reduce', 1),\n",
        " ('relaxing', 1),\n",
        " ('released', 1),\n",
        " ('remind', 1),\n",
        " ('removed', 1),\n",
        " ('request', 1),\n",
        " ('requires', 1),\n",
        " ('rest', 1),\n",
        " ('restaurant', 1),\n",
        " ('return', 1),\n",
        " ('rhyme', 1),\n",
        " ('rip', 1),\n",
        " ('rise', 1),\n",
        " ('rising', 1),\n",
        " ('rotten', 1),\n",
        " ('sang', 1),\n",
        " ('santla', 1),\n",
        " ('satan', 1),\n",
        " ('saying', 1),\n",
        " ('scheduled', 1),\n",
        " ('scientologyist', 1),\n",
        " ('scoring', 1),\n",
        " ('screw', 1),\n",
        " ('secret', 1),\n",
        " ('secure', 1),\n",
        " ('secured', 1),\n",
        " ('seen', 1),\n",
        " ('sees', 1),\n",
        " ('serve', 1),\n",
        " ('setting', 1),\n",
        " ('setup', 1),\n",
        " ('sexy', 1),\n",
        " ('share', 1),\n",
        " ('sharing', 1),\n",
        " ('shoot', 1),\n",
        " ('shut', 1),\n",
        " ('sick', 1),\n",
        " ('sighn', 1),\n",
        " ('sign', 1),\n",
        " ('singing', 1),\n",
        " ('site', 1),\n",
        " ('sitting', 1),\n",
        " ('sixteen', 1),\n",
        " ('sleep', 1),\n",
        " ('sleeping', 1),\n",
        " ('slept', 1),\n",
        " ('smarten', 1),\n",
        " ('soda', 1),\n",
        " ('something', 1),\n",
        " ('sometime', 1),\n",
        " ('sos', 1),\n",
        " ('sounds', 1),\n",
        " ('spell', 1),\n",
        " ('spent', 1),\n",
        " ('spilled', 1),\n",
        " ('staging', 1),\n",
        " ('starts', 1),\n",
        " ('stick', 1),\n",
        " ('stocking', 1),\n",
        " ('stood', 1),\n",
        " ('stored', 1),\n",
        " ('stranded', 1),\n",
        " ('strikes', 1),\n",
        " ('striking', 1),\n",
        " ('stubborn', 1),\n",
        " ('stupid', 1),\n",
        " ('sue', 1),\n",
        " ('suffering', 1),\n",
        " (\"sun's\", 1),\n",
        " ('support', 1),\n",
        " ('suppose', 1),\n",
        " ('surged', 1),\n",
        " ('survive', 1),\n",
        " ('survived', 1),\n",
        " ('swimming', 1),\n",
        " ('taken', 1),\n",
        " ('talked', 1),\n",
        " ('talking', 1),\n",
        " ('tavfx', 1),\n",
        " ('telling', 1),\n",
        " ('tempered', 1),\n",
        " ('term', 1),\n",
        " ('thank', 1),\n",
        " ('thanking', 1),\n",
        " ('thanks', 1),\n",
        " ('thanksgetting', 1),\n",
        " ('thinks', 1),\n",
        " ('thought', 1),\n",
        " ('threating', 1),\n",
        " ('threw', 1),\n",
        " ('tie', 1),\n",
        " (\"titanc's\", 1),\n",
        " ('tm', 1),\n",
        " ('tomorrow', 1),\n",
        " ('torture', 1),\n",
        " ('town', 1),\n",
        " ('trace', 1),\n",
        " ('trapping', 1),\n",
        " ('traveling', 1),\n",
        " ('tricks', 1),\n",
        " ('trips', 1),\n",
        " ('true', 1),\n",
        " ('turn', 1),\n",
        " ('turning', 1),\n",
        " ('typed', 1),\n",
        " ('uncheck', 1),\n",
        " ('unite', 1),\n",
        " ('unnerving', 1),\n",
        " ('unsure', 1),\n",
        " ('unwrapped', 1),\n",
        " ('upsetting', 1),\n",
        " ('uses', 1),\n",
        " ('valued', 1),\n",
        " ('veiw', 1),\n",
        " ('view', 1),\n",
        " ('visit', 1),\n",
        " ('vitaeneed', 1),\n",
        " ('vote', 1),\n",
        " ('vs', 1),\n",
        " ('waiting', 1),\n",
        " ('wake', 1),\n",
        " ('walk', 1),\n",
        " ('walked', 1),\n",
        " ('wana', 1),\n",
        " ('wandering', 1),\n",
        " ('wanna', 1),\n",
        " ('wanting', 1),\n",
        " ('wants', 1),\n",
        " ('warning', 1),\n",
        " ('wasnt', 1),\n",
        " ('waste', 1),\n",
        " ('watched', 1),\n",
        " ('watching', 1),\n",
        " ('wear', 1),\n",
        " ('websites', 1),\n",
        " ('weighs', 1),\n",
        " ('welcome', 1),\n",
        " ('whaqt', 1),\n",
        " ('whom', 1),\n",
        " ('wifi', 1),\n",
        " ('winning', 1),\n",
        " ('wishing', 1),\n",
        " ('woke', 1),\n",
        " ('wondered', 1),\n",
        " ('wont', 1),\n",
        " ('workwhat', 1),\n",
        " ('wouldnt', 1),\n",
        " ('wrap', 1),\n",
        " ('wrapped', 1),\n",
        " ('writes', 1),\n",
        " ('writing', 1),\n",
        " ('wrong', 1),\n",
        " ('wrote', 1),\n",
        " ('wud', 1),\n",
        " ('ya', 1),\n",
        " ('yahoo', 1),\n",
        " ('zipper', 1),\n",
        " ('zoe', 1)]"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verb_tuples = []\n",
      "\n",
      "for sent in text_tag:\n",
      "    for word in sent:\n",
      "        if word[1][0] == 'N':\n",
      "            verb_tuples.append(word)\n",
      "            \n",
      "tag_fd = nltk.FreqDist(noun_tuples)\n",
      "tag_fd.items()[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# np = sentence_tagging(sents)\n",
      "#     tagged_sent = ngram_tagger.tag(words)\n",
      "#     text_tag.append(tagged_sent)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Using Dialogue Act Types: NPS Chat Corpus **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- need to turn the following into a class. \n",
      "- def: to do the parsing\n",
      "- def: to see if it contains certain posts from nps chat corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dialogue_act_features(post):\n",
      "    features = {}\n",
      "    for word in nltk.word_tokenize(post):\n",
      "        features['contains(%s)' % word.lower()] = True\n",
      "    return features\n",
      "\n",
      "dialogue_act_features('why do human have five fingers and five toes?')\n",
      "\n",
      "#Creating Training Set\n",
      "#post.get('class') takes the 15 dialogue act types: statement, emotion, ynQuestion, continuer..\n",
      "\n",
      "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
      "               for post in posts]\n",
      "\n",
      "training_set_cps_chat = featuresets\n",
      "\n",
      "#Train Classifier\n",
      "classifier = nltk.NaiveBayesClassifier.train(training_set_cps_chat)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Test Classifier\n",
      "#print nltk.classify.accuracy(classifier, sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'str' object has no attribute 'copy'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-18-07e9c1487f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Test Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/nltk/classify/util.pyc\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(classifier, gold)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/nltk/classify/api.pyc\u001b[0m in \u001b[0;36mbatch_classify\u001b[0;34m(self, featuresets)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatch_prob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/nltk/classify/naivebayes.pyc\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, featureset)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/nltk/classify/naivebayes.pyc\u001b[0m in \u001b[0;36mprob_classify\u001b[0;34m(self, featureset)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Otherwise, we'll just assign a probability of 0 to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# everything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mfeatureset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'copy'"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nps_chat.posts('10-19-20s_706posts.xml')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['now', 'im', 'left', 'with', 'this', 'gay', 'name'], [':P'], ...]\n"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print featuresets[:10]\n",
      "\n",
      "'''sample from the text book'''\n",
      "#size = int(len(featuresets) * 0.1)\n",
      "#classifer = nltk.NaiveBayesClassifier.train(featuresets)\n",
      "#print nltk.classify.accuracy(classifer, sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[({'contains(im)': True, 'contains(now)': True, 'contains(this)': True, 'contains(left)': True, 'contains(name)': True, 'contains(with)': True, 'contains(gay)': True}, 'Statement'), ({'contains(:)': True, 'contains(p)': True}, 'Emotion'), ({'contains(part)': True}, 'System'), ({'contains(hey)': True, 'contains(everyone)': True}, 'Greet'), ({'contains(well)': True, 'contains(ah)': True}, 'Statement'), ({'contains(:10-19-20suser7)': True, 'contains(nick)': True}, 'System'), ({'contains(is)': True, 'contains(a)': True, 'contains(.)': True, 'contains(name)': True, 'contains(10-19-20suser7)': True, 'contains(gay)': True}, 'Accept'), ({'contains(a)': True, 'contains(.action)': True, 'contains(10-19-20suser121)': True, 'contains(gives)': True, 'contains(clap)': True, 'contains(golf)': True, 'contains(.)': True}, 'System'), ({'contains(:)': True, 'contains())': True}, 'Emotion'), ({'contains(join)': True}, 'System')]\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#train on the whole cps_chat corpus\n",
      "classifer = nltk.NaiveBayesClassifier.train(featuresets)\n",
      "\n",
      "#how do I incorporate this into a feature?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Movie Reviews **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import movie_reviews\n",
      "\n",
      "movie_reviews"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "encoding() takes exactly 2 arguments (1 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-32-3671d5f8caf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmovie_reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: encoding() takes exactly 2 arguments (1 given)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Other Notes: **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Add all features from above into Extractor **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor = util.FeatureExtractor()\n",
      "extractor.add_extractor(worder)\n",
      "extractor.add_extractor(colo, trained=True)\n",
      "#extractor.add_extractor(check_propnouns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.classify.NaiveBayesClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.test(sample_sets, confusion=True, folds=10, classifier=classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "**************************\n",
        "Run 0\n",
        "**************************\n",
        "test 0 - 79.554%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      3      2      4      5      6      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <14.1%>     .   3.0%   6.7%   1.9%   1.5%   1.5% |\n",
        "3 |      . <16.0%>  0.7%   0.7%      .      .   0.4% |\n",
        "2 |   0.4%      . <13.0%>     .      .      .      . |\n",
        "4 |      .      .      . <12.3%>     .      .      . |\n",
        "5 |      .      .      .      .  <9.7%>  0.4%   0.7% |\n",
        "6 |      .      .      .   0.7%      .  <8.2%>     . |\n",
        "7 |      .      .      .   1.1%      .   0.7%  <6.3%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-21-f9538119c54c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/jennylo/Documents/Local_Repositories/INFO253_NLP/nlp2014_kaggle/testing_util.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, samples, folds, classifier, num_tests, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Run {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"**************************\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mfold_test_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jennylo/Documents/Local_Repositories/INFO253_NLP/nlp2014_kaggle/testing_util.py\u001b[0m in \u001b[0;36mfold_test_extractor\u001b[0;34m(feature_extractor, samples, folds, classifier, confusion, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jennylo/Documents/Local_Repositories/INFO253_NLP/nlp2014_kaggle/testing_util.py\u001b[0m in \u001b[0;36mget_classifier\u001b[0;34m(self, samples, classifier)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_extractors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jennylo/Documents/Local_Repositories/INFO253_NLP/nlp2014_kaggle/testing_util.py\u001b[0m in \u001b[0;36mmake_classifier\u001b[0;34m(feature_extractor, train, classifier)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mtests\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jennylo/Documents/Local_Repositories/INFO253_NLP/nlp2014_kaggle/testing_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-3-d36cf7de314a>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"{}has({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    141\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(*key)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;31m# invalid expression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/sre_compile.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# internal: convert pattern list to internal format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/sre_compile.pyc\u001b[0m in \u001b[0;36misstring\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors = extractor.show_errors(sample_sets, classifier=classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for e in errors:\n",
      "    #if e[1]==\"2\":\n",
      "        print e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('1', '7', 'why do men have nipples? ')\n",
        "('1', '5', 'what is a nice gift for my sister? she is 32 has two boys and she is studying to be a minister')\n",
        "('4', '1', 'when do you know you are in love? ')\n",
        "('6', '3', 'why is e-mail the same as a penis? ')\n",
        "('1', '2', 'can nyone have documentation on online shopping ? ')\n",
        "('1', '4', 'is there anyone for me? ')\n",
        "('2', '6', 'why old people always are complaining ? like my grandma for example: i dont like this ice cream is not tasty when the ice cream was really good.')\n",
        "('4', '3', \"who had the shortest celebrity marriage? nikki hilton's and renee zellwegger's super-short marriages this year got me thinking-- which celebrity had the shortest marriage of all time?\")\n",
        "('4', '3', 'is anyone else in total love/lust with sara silverman? ')\n",
        "('1', '6', 'what is highest live expectancy in the world? ')\n",
        "('1', '7', \"what does the time dimension of a sphere look like? (or rather, how is it percieved?)? the time dimension is accepted as the 4th dimension. if you have an idea about it or even another question that you would think i would find interesting, i'd like to hear it. thanks.\")\n",
        "('1', '2', 'what is the max file size on unix? ')\n",
        "('1', '6', 'what is the best way to get rid of heart burn? ')\n",
        "('1', '3', 'how old is juicy j from the  rap group  three 6 mafia? ')\n",
        "('1', '5', 'is yahoo or google a better resource for research? what is another good resource for academic research? thanks.')\n",
        "('1', '7', \"how do fire act in 'zero gravity'? \")\n",
        "('2', '1', \"is it really necessary to have a copyright date?  won't copyright alone suffice? this is in regards to copyright notices at the bottom of webpages.\")\n",
        "('1', '3', 'beyonce, mariah or j-lo? ')\n",
        "('1', '3', 'what is brown and sticky? ')\n",
        "('1', '6', 'where can you get an hha for free if the insurance doesnt cover it? my mothers insurance denied her right to an hha.  we have no money to pay privately and she despirately needs it')\n",
        "('1', '7', 'what is the only state in the us whose governor has no veto power? ')\n",
        "('1', '4', 'what do i do if the 2 guys i like both asked me out on the same day who should i go with? ')\n",
        "('2', '1', 'why do you think yahoo! answers is so addictive? is it the interface, the point scoring, competition, or what?')\n",
        "('1', '7', 'please find for me the force acted upon by an infinite conducting plane on a dipole.? a point dipole with dipole moment p is located at a distance l from an infinite conducting plane.find the modulus of the vector of electric interaction force acting on the dipole if the dipole moment vector is perpendicular to the plane.please help me here along with the concepts applied here.')\n",
        "('4', '1', 'who likes zoe girl? ')\n",
        "('1', '4', \"how do i no my ex isnt goin 2 lie 2 me anymore? i havent forgiven him yet but i want 2 . help!? he's lied to me before and i didnt forgive him. he says he was high and drunk whenever he did this but i dont believe him. i've known him for 8 years, we grew up together and he never lied to me before. but he made a mistake and lied to me about a lot of stuff. do i forgive him or not?\")\n",
        "('1', '7', 'why do we yawn? how is it contagious...')\n",
        "('5', '2', \"how to erase all the words i've been searched from the yahoo search? \")\n",
        "('1', '3', 'if u could only watch one tv a week what would it be? ')\n",
        "('1', '5', 'why is it important to separate current liabilities from long term liabilities? ')\n",
        "('1', '4', 'i have a husband and im paying 95% of the bill should i dump him? ')\n",
        "('1', '4', \"there's this older guy that i like...how do i get him to notice me? i'm not particularly pretty but i really like this man but i'm not sure he'll like me the same.  any advise on how the ugly duckling can capture the handsome frog's heart?\")\n",
        "('1', '5', 'what ncaa sport does not have a playoff system? ')\n",
        "('5', '1', \"what is a 'surry' ? this isn't a mis-spelling of 'surrey', but apparently a word in its own right.\")\n",
        "('1', '2', 'i know an email address but forgot the @ part. how do i find the email address if all i know is the begining? ')\n",
        "('1', '3', 'i need telugu devotional free ringtones where i have to find? devotional')\n",
        "('2', '1', 'i want to see all the company director and there e-maill address in saudi arabia? i want to know them')\n",
        "('4', '1', 'me and my boyfriend have been going out for a week. will we last? ')\n",
        "('1', '2', 'how to i get yahoo! to make it reasonably easy to ask support questions and have them respond meaningfully? - all people ever get is an automated response that, in my experience, never answers the question&#xa;- why must they make it so difficult?')\n",
        "('1', '6', \"does labour become more difficult if i've gained 20 pounds by the end of my 7th month already? plus i wanna know what contractions really feel like...i've started my 8th month and wanna know how they feel cuz i still have no idea\")\n",
        "('1', '2', 'how to fool an ip address tracer into believeing another ip? how to change ip address from original to another, but our own choice.&#xa;&#xa;http://cs.dal.ca/~koul/')\n",
        "('1', '2', 'what is rss? ')\n",
        "('3', '1', 'what should i do to find a good job? every time i look for a job the employers ask me for referers but this is my first time i would work.')\n",
        "('1', '7', 'is dna the real map from where we come from and where we go to???? ')\n",
        "('2', '5', 'which part-time mba program will add value to a software developer with 15 years experience? ')\n",
        "('1', '5', 'what sea creature sleeps with one eye open? ')\n",
        "('1', '5', 'what is meaning of shivani? ')\n",
        "('1', '4', 'do you enjoy reading erotic stories? ')\n",
        "('1', '4', 'forgive and forget? is it possible to forgive and forget a cheater?')\n",
        "('4', '3', \"do the backstreet boys have a chance on their comeback? did their little hiatus hurt their careers or can they start from scratch? i really don't care; i'm just throwing out the first thing that pops into my head.\")\n",
        "('1', '3', 'who is eddie van halen? ')\n",
        "('1', '4', 'how do house chores get divided in your family? ')\n",
        "('4', '1', 'did you ever have alot of guys ask you out in at least 20 min? i did i want to see if its normal for a girl')\n",
        "('1', '6', 'how many times is go toget upset during a day? why i am getting upset?&#xa;why i can not save money although i am working?&#xa;why i always feel lonly?')\n",
        "('1', '7', 'why salt will be spread on snowy days? ')\n",
        "('2', '1', \"why did yahoo close my 4 year old id for no reason and with no warning? all my points gone, my email, just really irritating to try to sign in and have no idea why it isn't working and then get a place that says your account is deactivated. i think it may be a defect in 360 because it kept asking me to login last 4 days but the login would never take.\")\n",
        "('1', '3', 'how many instruments would be considered to much for someone to practice? ')\n",
        "('1', '2', 'i need help on how to put flash videos on ur page,but i dont kno how to,and i need help on what a swf is??help im on this site and i want to put still tippin by paul wall,on my bebo page! but i dontknow how to,and the director of bebo wont help me..so can u ppl help me..please!!!! i  dont kno what a swf is,and i want to put the flash still tippin/by paul wall on my page!!...please....please....please help me!!!!!!!!!!!')\n",
        "('1', '4', \"does a woman's size matter? peaople always ask does size matter? referring to men, but what about a woman's size, does that matter?\")\n",
        "('4', '3', 'are there proofs of homosexuality b/w batman &amp; robin? ')\n",
        "('1', '3', \"how do you circumsize a redneck? it is the funniest joke i've ever heard\")\n",
        "('1', '3', \"brothers and sisters, i have none. this man's father is my father's son. who am i? \")\n",
        "('1', '5', 'know an easy way to remember when to use affect and effect? ')\n",
        "('1', '3', \"in the rugrats go to paris how did chuckie's mom die? \")\n",
        "('1', '2', 'what is the best place, in this game called maple story, to train? ')\n",
        "('2', '3', \"music html? hi...i was wondering if anyone knew of a good site that allows you to get the html address for mp3's??. i know you can download music offline, but that's not what i'm looking for. i simply just need a html address from a mp3 to put in my profile on myspace...any suggestions would be appreciated.&#xa;&#xa;p.s. i use to go to cdzinc.com all the time, but it's currently under construction, so i need another place to get them from. :) - thanx.\")\n",
        "('2', '1', 'what are some of the advantages of participating in a regular exercise  program? ')\n",
        "('1', '6', 'what causes the irritation around the ileostomy? what to do? ')\n",
        "('2', '6', \"anybody outthere with a shoulder problem(s) tellme how are you doing mine is a nightmare answer soon? i have had 2 surgeries on the same shoulder and it is a complete nightmare it feels like i' never be able to use my right arm it has been a year and i dont feel no changes wanna know if there's any body with the same problem.\")\n",
        "('2', '1', 'which company owns kraft foods? i heard it was a non-foods company')\n",
        "('1', '3', 'who was famous for the line nanoo nanoo? ')\n",
        "('1', '2', 'what is the best free c/c++ ide for solaris excluding vi and emacs? ')\n",
        "('1', '2', 'my prymary wsus server can not see the clients attached its down stream wsus servers. any suggestions? my prymary wsus server can not see the clients attached its down stream wsus servers. any suggestions')\n",
        "('1', '3', \"what's the name of paris hilton's pet dog? \")\n",
        "('1', '7', 'what is the oldest evidence of life? ')\n",
        "('1', '6', \"what is that tiny pinhole near the top of someone's ear near the temple? i have seen this maybe 3 or 4 times \")\n",
        "('5', '2', 'why do schools have stupid internet locks.? ')\n",
        "('1', '5', \"when you're in someone's disfavor, you are in this backyard object? \")\n",
        "('1', '7', \"'intelligent design' should be better named 'malevolent design'. do you agree ? \")\n",
        "('1', '4', 'how can u say im sori to da guy dat u hurt so much..he doesnt even wana tok to u???!!!*tears*? ')\n",
        "('1', '5', 'where on the net can i find step by step instructions on toothpick bridge building? ')\n",
        "('1', '3', 'do you think giada de laurentiis is hot? ')\n",
        "('1', '5', 'where is the  rhetorical device in this sentence? where is the rhetorical device in this sentence? the majority of americans will think that stronger drug abuse laws should be passed.')\n",
        "('6', '1', \"how long does midlife crisis last? my ex started acting out before we got divorced by doing stupid things like smoking pot all the time and getting oui's, he's still at it, being stupid and getting his a$$ arrested for dumb things, after about 6 years.  is this a midlife crisis, or is it just self destructive stupid behavior?  he's now 38, who thinks he will smarten up or what?\")\n",
        "('4', '3', \"i can't remember the name of the villain who would always tie dudley doright's girlfriend to traintracks?? \")\n",
        "('1', '4', 'how to convince people who are irresponsible? ')\n",
        "('1', '6', 'what is the psychological term or disorder, for people who see imaginary people or animals? ')\n",
        "('1', '7', 'what is the predicate logic? ')\n",
        "('1', '2', 'how i can install php on xp? ')\n",
        "('1', '2', 'why i can open the ecard from 123greetings.com? ')\n",
        "('1', '5', 'what is the difference between a bachelors and a masters degree? ')\n",
        "('2', '1', 'should us computer programmers be worried about outsourcing trend to india and other countries? ')\n",
        "('3', '2', 'i installed 64mb ram in ibm thinkpad it only reconized 40mb can anyone help with this? self diagnostic test shows 64mb ram but system mech, memory king, and win 98 al only show 40mb i am confused')\n",
        "('5', '1', 'how to get pass word of my yahoo id if i have forgotten details provided at the time of ragistration? ')\n",
        "('1', '6', 'what can you say to someone on their deathbed to help put their mind at ease? ')\n",
        "('2', '1', 'where is the best place online to find business partners for an it startup? i am currently looking for great technical partners for a new internet and it startup.  i already know about gobignetwork.com, but i was hoping to find out about similar websites or ways to find great people.')\n",
        "('1', '2', 'why do users in yahoo! 360 have almost no friends? the majority of yahoo 360 users have zero friend.')\n",
        "('1', '2', 'do you need to pay for mac os x remote desktop (client)? if so - what are some alternatives? (not vnc).? ')\n",
        "('1', '2', 'i dont understand smtp (iis) xp?? pleeeeaase?&#xa;i want details?')\n",
        "('4', '6', \"i'm a women with gential warts,partner left  afraid to be a lone for life due to condition any advise? \")\n",
        "('1', '6', 'how do you cure constipation? without having massive diarrhea.')\n",
        "('1', '7', \"how do a fish's gills extract oxygen? \")\n",
        "('1', '6', 'what store can i buy jovan ginseng? ')\n",
        "('1', '5', 'what should the serving temp. of coffee be ?? ')\n",
        "('1', '5', 'which search engine has a mascot named arfie? ')\n",
        "('1', '4', 'how can men hold their orgasms? ')\n",
        "('1', '2', 'simple dos  graphics using c? hi, &#xa;  what should i learn to create simple dos graphics by controlling pixels on the monitor. i already know how to control pixels in assembly, but i wanted it in c')\n",
        "('2', '7', 'how can i make a phone call to argentina? besides the local phone number, what are the other numbers i might have to compose to get in contact with someone from buenos aires?  also, what is the format of an argentinian phone number (in canada it would be ###-####)')\n",
        "('1', '3', \"is it's a wonderful life on tv over the next few days before christmas? \")\n",
        "('4', '1', \"why can't women just see things our way and like it?????? \")\n",
        "('1', '7', 'does having light coloured eyes make you ahve better night vision? ')\n",
        "('1', '4', 'what can a male do to be more affectionate? ')\n",
        "('1', '6', 'why do non-vegetarians get so defensive at the mere mention that one is a vegetarian? ')\n",
        "('1', '5', 'how to get rid of a beehive? who can tell me how to get rid of a beehive with out getting stung?')\n",
        "('6', '5', 'cold turkey? where and how did the term cold turkey originate? what was its original meaning?')\n",
        "('1', '5', 'why do all zippers have ykk on them? ')\n",
        "('1', '2', \"what is 'answers.yahoo.com'? \")\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_features = util.make_feature(extractor, final_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = util.make_classifier(extractor, sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.show_most_informative_features(200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "               has(love) = 1                   4 : 2      =     35.8 : 1.0\n",
        "               has(pain) = 1                   6 : 1      =     34.1 : 1.0\n",
        "                has(sex) = 1                   4 : 2      =     33.5 : 1.0\n",
        "              has(music) = 1                   3 : 1      =     30.9 : 1.0\n",
        "               has(girl) = 1                   4 : 7      =     28.6 : 1.0\n",
        "               has(song) = 1                   3 : 1      =     26.8 : 1.0\n",
        "       has(relationship) = 1                   4 : 1      =     25.2 : 1.0\n",
        "              has(movie) = 1                   3 : 4      =     22.5 : 1.0\n",
        "            has(college) = 1                   5 : 2      =     20.4 : 1.0\n",
        "            has( friend) = 1                   4 : 5      =     20.0 : 1.0\n",
        "                has(boy) = 1                   4 : 5      =     19.5 : 1.0\n",
        "              has(medic) = 1                   6 : 1      =     19.1 : 1.0\n",
        "   has((boy|girl)friend) = 1                   4 : 6      =     19.0 : 1.0\n",
        "           has(internet) = 1                   2 : 3      =     18.8 : 1.0\n",
        "               has(rock) = 1                   3 : 1      =     18.3 : 1.0\n",
        "              has(study) = 1                   5 : 1      =     17.8 : 1.0\n",
        "            has(program) = 1                   2 : 3      =     17.0 : 1.0\n",
        "              has(marri) = 1                   4 : 1      =     16.7 : 1.0\n",
        "           has(software) = 1                   2 : 1      =     16.6 : 1.0\n",
        "              has(blood) = 1                   6 : 1      =     16.5 : 1.0\n",
        "             has(school) = 1                   5 : 2      =     16.0 : 1.0\n",
        "                has(web) = 1                   2 : 6      =     15.9 : 1.0\n",
        "               has(cold) = 1                   6 : 3      =     15.7 : 1.0\n",
        "               has(math) = 1                   7 : 1      =     15.6 : 1.0\n",
        "       has(smok(es|ing)) = 1                   6 : 1      =     14.3 : 1.0\n",
        "              has(grade) = 1                   5 : 1      =     13.6 : 1.0\n",
        "               has(moon) = 1                   7 : 1      =     13.5 : 1.0\n",
        "            has(windows) = 1                   2 : 5      =     12.8 : 1.0\n",
        "            has(episode) = 1                   3 : 1      =     12.0 : 1.0\n",
        "           has(magazine) = 1                   3 : 1      =     12.0 : 1.0\n",
        "            has(english) = 1                   5 : 2      =     11.8 : 1.0\n",
        "              has(teach) = 1                   5 : 2      =     11.8 : 1.0\n",
        "            has(science) = 1                   7 : 1      =     11.4 : 1.0\n",
        "             has(weight) = 1                   6 : 1      =     11.2 : 1.0\n",
        "           has(wireless) = 1                   2 : 1      =     10.7 : 1.0\n",
        "              has(women) = 1                   4 : 5      =     10.6 : 1.0\n",
        "               has(wife) = 1                   4 : 1      =     10.2 : 1.0\n",
        "             has(health) = 1                   6 : 1      =      9.9 : 1.0\n",
        "              has(earth) = 1                   7 : 4      =      9.9 : 1.0\n",
        "             has(riddle) = 1                   3 : 1      =      9.5 : 1.0\n",
        "            has(spanish) = 1                   5 : 1      =      9.4 : 1.0\n",
        "               has(show) = 1                   3 : 6      =      9.4 : 1.0\n",
        "               has(date) = 1                   4 : 3      =      9.1 : 1.0\n",
        "            has(e-?mail) = 1                   2 : 3      =      8.8 : 1.0\n",
        "           has(download) = 1                   2 : 1      =      8.5 : 1.0\n",
        "               has(cure) = 1                   6 : 2      =      8.5 : 1.0\n",
        "              has(point) = 1                   7 : 3      =      8.2 : 1.0\n",
        "             has(educat) = 1                   5 : 1      =      8.2 : 1.0\n",
        "           has(favorite) = 1                   3 : 1      =      8.1 : 1.0\n",
        "               has(comp) = 1                   2 : 4      =      7.6 : 1.0\n",
        "            has(website) = 1                   2 : 7      =      7.4 : 1.0\n",
        "            has(history) = 1                   5 : 3      =      7.2 : 1.0\n",
        "             has(theory) = 1                   7 : 3      =      7.1 : 1.0\n",
        "           has(universe) = 1                   7 : 3      =      7.1 : 1.0\n",
        "             has(planet) = 1                   7 : 2      =      6.7 : 1.0\n",
        "             has(family) = 1                   4 : 1      =      6.6 : 1.0\n",
        "              has(penis) = 1                   6 : 3      =      6.4 : 1.0\n",
        "              has(money) = 1                   1 : 7      =      6.3 : 1.0\n",
        "          has(treatment) = 1                   6 : 7      =      6.0 : 1.0\n",
        "             has(credit) = 1                   1 : 3      =      5.8 : 1.0\n",
        "               has(body) = 1                   6 : 7      =      5.7 : 1.0\n",
        "           has(business) = 1                   1 : 4      =      5.3 : 1.0\n",
        "               has(word) = 1                   5 : 1      =      5.1 : 1.0\n",
        "               has(book) = 1                   5 : 3      =      5.0 : 1.0\n",
        "            has(cartoon) = 1                   3 : 1      =      4.9 : 1.0\n",
        "               has(diet) = 1                   6 : 7      =      4.6 : 1.0\n",
        "               has(exam) = 1                   2 : 1      =      4.4 : 1.0\n",
        "              has(stars) = 1                   7 : 2      =      4.3 : 1.0\n",
        "            has(husband) = 1                   4 : 1      =      4.2 : 1.0\n",
        "              has(first) = 1                   3 : 1      =      4.1 : 1.0\n",
        "       has(act(or|ress)) = 1                   3 : 1      =      4.0 : 1.0\n",
        "             has(dating) = 1                   4 : 3      =      4.0 : 1.0\n",
        "              has(world) = 1                   7 : 6      =      4.0 : 1.0\n",
        "      has(\\d+(mb|kb|gb)) = 1                   2 : 3      =      3.9 : 1.0\n",
        "               has(atom) = 1                   7 : 3      =      3.8 : 1.0\n",
        "      has(\\d+[/*^+-]\\d+) = 1                   2 : 4      =      3.8 : 1.0\n",
        "             has(series) = 1                   3 : 2      =      3.8 : 1.0\n",
        "              has(learn) = 1                   5 : 1      =      3.6 : 1.0\n",
        "             has(singer) = 1                   3 : 5      =      3.4 : 1.0\n",
        "               has(sell) = 1                   1 : 6      =      3.3 : 1.0\n",
        "      has(roman(ce|tic)) = 1                   4 : 3      =      2.6 : 1.0\n",
        "            has(itching) = 1                   6 : 4      =      2.5 : 1.0\n",
        "               has(acne) = 1                   6 : 4      =      2.5 : 1.0\n",
        "collocatorhas('united', 'states') = 1                   1 : 3      =      2.3 : 1.0\n",
        "               has(html) = 1                   2 : 3      =      2.0 : 1.0\n",
        "               has(love) = 0                   7 : 4      =      1.2 : 1.0\n",
        "               has(girl) = 0                   2 : 4      =      1.2 : 1.0\n",
        "               has(comp) = 0                   4 : 2      =      1.2 : 1.0\n",
        "   has((boy|girl)friend) = 0                   2 : 4      =      1.1 : 1.0\n",
        "            has( friend) = 0                   7 : 4      =      1.1 : 1.0\n",
        "                has(boy) = 0                   2 : 4      =      1.1 : 1.0\n",
        "                has(sex) = 0                   7 : 4      =      1.1 : 1.0\n",
        "                has(web) = 0                   6 : 2      =      1.1 : 1.0\n",
        "              has(movie) = 0                   5 : 3      =      1.1 : 1.0\n",
        "               has(song) = 0                   1 : 3      =      1.1 : 1.0\n",
        "             has(school) = 0                   1 : 5      =      1.1 : 1.0\n",
        "       has(relationship) = 0                   1 : 4      =      1.1 : 1.0\n",
        "            has(windows) = 0                   1 : 2      =      1.1 : 1.0\n",
        "              has(marri) = 0                   2 : 4      =      1.1 : 1.0\n",
        "            has(college) = 0                   3 : 5      =      1.1 : 1.0\n",
        "           has(internet) = 0                   7 : 2      =      1.1 : 1.0\n",
        "               has(pain) = 0                   3 : 6      =      1.1 : 1.0\n",
        "              has(women) = 0                   2 : 4      =      1.1 : 1.0\n",
        "               has(word) = 0                   4 : 5      =      1.1 : 1.0\n",
        "              has(medic) = 0                   2 : 6      =      1.1 : 1.0\n",
        "            has(program) = 0                   4 : 2      =      1.1 : 1.0\n",
        "              has(music) = 0                   1 : 3      =      1.1 : 1.0\n",
        "               has(cold) = 0                   2 : 6      =      1.1 : 1.0\n",
        "               has(show) = 0                   7 : 3      =      1.1 : 1.0\n",
        "           has(favorite) = 0                   4 : 3      =      1.1 : 1.0\n",
        "               has(date) = 0                   7 : 4      =      1.1 : 1.0\n",
        "           has(software) = 0                   4 : 2      =      1.1 : 1.0\n",
        "            has(e-?mail) = 0                   7 : 2      =      1.1 : 1.0\n",
        "               has(body) = 0                   7 : 6      =      1.1 : 1.0\n",
        "           has(download) = 0                   4 : 2      =      1.1 : 1.0\n",
        "              has(first) = 0                   1 : 3      =      1.0 : 1.0\n",
        "              has(world) = 0                   2 : 7      =      1.0 : 1.0\n",
        "              has(earth) = 0                   3 : 7      =      1.0 : 1.0\n",
        "              has(teach) = 0                   3 : 5      =      1.0 : 1.0\n",
        "            has(website) = 0                   7 : 2      =      1.0 : 1.0\n",
        "          has(treatment) = 0                   1 : 6      =      1.0 : 1.0\n",
        "            has(english) = 0                   6 : 5      =      1.0 : 1.0\n",
        "             has(weight) = 0                   2 : 6      =      1.0 : 1.0\n",
        "               has(rock) = 0                   2 : 3      =      1.0 : 1.0\n",
        "              has(study) = 0                   2 : 5      =      1.0 : 1.0\n",
        "            has(surgery) = 0                   1 : 6      =      1.0 : 1.0\n",
        "               has(wife) = 0                   2 : 4      =      1.0 : 1.0\n",
        "              has(blood) = 0                   2 : 6      =      1.0 : 1.0\n",
        "             has(health) = 0                   2 : 6      =      1.0 : 1.0\n",
        "              has(money) = 0                   3 : 1      =      1.0 : 1.0\n",
        "              has(linux) = 0                   1 : 2      =      1.0 : 1.0\n",
        "               has(math) = 0                   2 : 7      =      1.0 : 1.0\n",
        "              has(learn) = 0                   4 : 5      =      1.0 : 1.0\n",
        "               has(book) = 0                   4 : 5      =      1.0 : 1.0\n",
        "              has(point) = 0                   4 : 7      =      1.0 : 1.0\n",
        "             has(laptop) = 0                   1 : 2      =      1.0 : 1.0\n",
        "             has(family) = 0                   2 : 4      =      1.0 : 1.0\n",
        "            has(husband) = 0                   2 : 4      =      1.0 : 1.0\n",
        "               has(diet) = 0                   1 : 6      =      1.0 : 1.0\n",
        "           has(symptoms) = 0                   1 : 6      =      1.0 : 1.0\n",
        "       has(smok(es|ing)) = 0                   2 : 6      =      1.0 : 1.0\n",
        "               has(cure) = 0                   3 : 6      =      1.0 : 1.0\n",
        "           has(universe) = 0                   1 : 7      =      1.0 : 1.0\n",
        "             has(theory) = 0                   1 : 7      =      1.0 : 1.0\n",
        "             has(educat) = 0                   2 : 5      =      1.0 : 1.0\n",
        "              has(grade) = 0                   3 : 5      =      1.0 : 1.0\n",
        "               has(moon) = 0                   1 : 7      =      1.0 : 1.0\n",
        "            has(history) = 0                   7 : 5      =      1.0 : 1.0\n",
        "             has(dating) = 0                   1 : 4      =      1.0 : 1.0\n",
        "              has(penis) = 0                   1 : 6      =      1.0 : 1.0\n",
        "             has(planet) = 0                   1 : 7      =      1.0 : 1.0\n",
        "           has(magazine) = 0                   2 : 3      =      1.0 : 1.0\n",
        "            has(episode) = 0                   2 : 3      =      1.0 : 1.0\n",
        "            has(science) = 0                   3 : 7      =      1.0 : 1.0\n",
        "           has(business) = 0                   3 : 1      =      1.0 : 1.0\n",
        "              has(lyric) = 0                   1 : 3      =      1.0 : 1.0\n",
        "             has(singer) = 0                   1 : 3      =      1.0 : 1.0\n",
        "             has(series) = 0                   1 : 3      =      1.0 : 1.0\n",
        "       has(act(or|ress)) = 0                   5 : 3      =      1.0 : 1.0\n",
        "              has(teeth) = 0                   1 : 6      =      1.0 : 1.0\n",
        "             has(credit) = 0                   2 : 1      =      1.0 : 1.0\n",
        "           has(wireless) = 0                   3 : 2      =      1.0 : 1.0\n",
        "               has(sell) = 0                   4 : 1      =      1.0 : 1.0\n",
        "         has(university) = 0                   1 : 5      =      1.0 : 1.0\n",
        "            has(spanish) = 0                   2 : 5      =      1.0 : 1.0\n",
        "             has(riddle) = 0                   2 : 3      =      1.0 : 1.0\n",
        "      has(roman(ce|tic)) = 0                   1 : 4      =      1.0 : 1.0\n",
        "            has(cartoon) = 0                   2 : 3      =      1.0 : 1.0\n",
        "              has(stars) = 0                   1 : 7      =      1.0 : 1.0\n",
        "               has(atom) = 0                   1 : 7      =      1.0 : 1.0\n",
        "      has(\\d+(mb|kb|gb)) = 0                   1 : 2      =      1.0 : 1.0\n",
        "               has(exam) = 0                   1 : 7      =      1.0 : 1.0\n",
        "      has(\\d+[/*^+-]\\d+) = 0                   4 : 2      =      1.0 : 1.0\n",
        "               has(html) = 0                   1 : 2      =      1.0 : 1.0\n",
        "              has(vomit) = 0                   1 : 6      =      1.0 : 1.0\n",
        "            has(itching) = 0                   1 : 6      =      1.0 : 1.0\n",
        "               has(acne) = 0                   1 : 6      =      1.0 : 1.0\n",
        "              has(\\d+mg) = 0                   1 : 6      =      1.0 : 1.0\n",
        "collocatorhas('united', 'states') = 0                   2 : 1      =      1.0 : 1.0\n",
        "               has(smtp) = 0                   1 : 2      =      1.0 : 1.0\n",
        "           has(materbat) = 0                   1 : 6      =      1.0 : 1.0\n",
        "          has(jokealbum) = 0                   1 : 6      =      1.0 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = util.make_submission(cl, final_features, writeto=\"submission25_jlo.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}