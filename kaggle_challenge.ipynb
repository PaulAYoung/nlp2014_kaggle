{
 "metadata": {
  "name": "",
  "signature": "sha256:894e7c5a81aa3ef7dafe787c3d4cdb813027ce29c67edfda76b05bdeb4752beb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import random\n",
      "from os import path\n",
      "\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_train = path.join(path.curdir, \"train.txt\")\n",
      "path_final_testing = path.join(path.curdir, \"test.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def file_to_sets(fname, ignore_header=True):\n",
      "    \"\"\"\n",
      "    Takes a file where each line is in the format \"category,text\" and turns it into a list of tuples\n",
      "    in format \"(category, text)\"\n",
      "    \"\"\"\n",
      "    \n",
      "    f = open(fname, 'r')\n",
      "    \n",
      "    if ignore_header:\n",
      "        # This skips the first line of the file\n",
      "        next(f)\n",
      "    \n",
      "    out = []\n",
      "    for line in f:\n",
      "        # iterate over lines, use simple regex to separate the category from text\n",
      "        out.append(re.match(r\"(\\d+),(.+$)\", line).groups())\n",
      "    \n",
      "    f.close()\n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_sets = file_to_sets(path_train, ignore_header=False)\n",
      "final_sets = file_to_sets(path_final_testing, ignore_header=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sets(samples, test_fraction=3):\n",
      "    \"\"\"\n",
      "    takes a set of samples, shuffles them, then returns two lists, train_sets and test_sets. \n",
      "    The size of test_sets is len(samples)/test_fraction, train_sets is the remainder. \n",
      "    \"\"\"\n",
      "    \n",
      "    test_size = int(len(samples)/test_fraction)\n",
      "    test_sets = samples[0:test_size]\n",
      "    train_sets = samples[test_size:]\n",
      "    \n",
      "    return train_sets, test_sets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_sets, test_sets = get_sets(sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FeatureExtractor(object):\n",
      "    \"\"\"A class to make it easy to combine and shuffle around feature extractors\"\"\"\n",
      "    \n",
      "    def __init__(self, extractors):\n",
      "        \"\"\"\n",
      "        Takes a list of extractors to use in extracting features. \n",
      "        Extractors should take a piece of text and return a dictionary where the key is\n",
      "        the desired key and the value is the feature value. \n",
      "        \"\"\"\n",
      "        if type(extractors) != 'list':\n",
      "            extractors = [extractors]\n",
      "        self.extractors = extractors\n",
      "        \n",
      "    def __call__(self, text):\n",
      "        features = {}\n",
      "        for e in self.extractors:\n",
      "            f = e(text)\n",
      "            for k, v in f.iteritems():\n",
      "                features[k]=v\n",
      "        \n",
      "        return features\n",
      "    \n",
      "    def add_extractor(self,extractor):\n",
      "        self.extractors.append(extractor)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "def get_terms(t):\n",
      "    tokens = nltk.word_tokenize(t)\n",
      "    return [w for w in tokens if w not in stopwords]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def category_term_scorer(sample_list):\n",
      "    \"\"\"\n",
      "    takes a list of tuples in format (category,text) and creates scores for each term\n",
      "    for its relevance to each category\n",
      "    \"\"\"\n",
      "    categories = {}\n",
      "    \n",
      "    for c,s in sample_list:\n",
      "        if c not in categories:\n",
      "            categories[c]=[]\n",
      "        for w in get_terms(s):\n",
      "            categories[c].append(w)\n",
      "    \n",
      "    fd_all = nltk.FreqDist([w for wl in categories.values() for w in wl])\n",
      "    \n",
      "    fd_categories = {c:nltk.FreqDist(v) for c,v in categories.iteritems()}\n",
      "    \n",
      "    term_scores = {}\n",
      "    for term in fd_all.iterkeys():\n",
      "        d = {}\n",
      "        for c,fd in fd_categories.iteritems():\n",
      "            d[c]= 1 if fd.freq(term) > fd_all.freq(term) else 0\n",
      "        term_scores[term]=d\n",
      "    \n",
      "    return term_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class TermScoreClassiffier(nltk.classify.ClassifierI):\n",
      "    \"\"\"\n",
      "    Tries to classify text using scored terms. \n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, samples=None, scorer=category_term_scorer, terms=None, key=\"TermScore\"):\n",
      "        \"\"\"\n",
      "        Params:\n",
      "        \n",
      "        samples -- a list of samples where each entry is a tuple in format (category,text)\n",
      "                this argument only works if scorer is also passed. \n",
      "                \n",
      "        scorer -- a function that takes the list of samples and scores them. Must return a dictionary\n",
      "                in the same format as terms\n",
      "        \n",
      "        terms -- a dictionary of terms where keys are the terms and values are dictionaries \n",
      "        with the score for each category. ie: {\"term\": {\"c1\":0, \"c2\":10}\n",
      "        \n",
      "        key -- The key to used in the returned dictionary. \n",
      "        \"\"\"\n",
      "        self.key = key\n",
      "        \n",
      "        if samples and scorer:\n",
      "            terms = scorer(samples)\n",
      "        \n",
      "        if not terms:\n",
      "            raise ValueError(\"You must either pass a list of samples or a list of terms\")\n",
      "        \n",
      "        self.terms = terms\n",
      "    \n",
      "    def __call__(self, text):\n",
      "        \"\"\"\n",
      "        Picks a category for text using the term list\n",
      "        \"\"\"\n",
      "        \n",
      "        tokens = nltk.word_tokenize(text)\n",
      "        scores = {}\n",
      "        for w in tokens:\n",
      "            if w in self.terms:\n",
      "                for c,s in self.terms[w].iteritems():\n",
      "                    if c in scores:\n",
      "                        scores[c] += s\n",
      "                    else:\n",
      "                        scores[c] = s\n",
      "        \n",
      "        totals = scores.items()\n",
      "        totals.sort(key= lambda s:s[1], reverse=True)\n",
      "        \n",
      "        return {self.key: setotals[0][0]}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = TermScoreClassiffier(train_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float(len([1 for s in test_sets if s[0] == classifier(s[1])]))/len(test_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "1799"
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}