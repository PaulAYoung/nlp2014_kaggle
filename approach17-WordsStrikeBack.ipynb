{
 "metadata": {
  "name": "",
  "signature": "sha256:54ff59265647d5191180d4977ee86a506c95ca1c734f22c368903a31da7ad9f2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import random\n",
      "from os import path\n",
      "\n",
      "import nltk\n",
      "\n",
      "import testing_util as util\n",
      "import term_scoring\n",
      "from testing_util import sample_sets, final_sets\n",
      "\n",
      "import tfidf_class"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class WordSearcher(object):\n",
      "    def __init__(self, wordlist=None, key=\"\", name=\"wordsearcher\"):\n",
      "        self.wordlist = wordlist if wordlist else []\n",
      "        self.key = key\n",
      "        self.__name__=name\n",
      "    \n",
      "    def add(self, wordlist):\n",
      "        self.wordlist.extend(wordlist)\n",
      "    \n",
      "    def clear(self):\n",
      "        self.wordlist = []\n",
      "    \n",
      "    def __call__(self, text):\n",
      "        out = {}\n",
      "        for word in self.wordlist:\n",
      "            out[\"{}has({})\".format(self.key, word)] = 1 if re.search(word, text, re.IGNORECASE) else 0\n",
      "        return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worder = WordSearcher()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worder.clear()\n",
      "#1-business\n",
      "#worder.add([\"money\", \"credit\", \"business\", \"sell\"])\n",
      "#2-computers\n",
      "worder.add([\"comp\", \"linux\", \"windows\", \"internet\",\n",
      "            \"software\", \"program\", r\"\\d+(mb|kb|gb)\",\n",
      "            \"download\", \"e-?mail\", \"web\", \"laptop\",\n",
      "            \"wireless\", \"website\", \"html\", \"smtp\"])\n",
      "#3 - entertainment\n",
      "worder.add([\"song\", \"movie\", \"music\", \"favorite\",\n",
      "            \"show\", \"first\", \"rock\", \"magazine\",\n",
      "            \"lyric\", \"series\", \"episode\", \"singer\",\n",
      "            \"act(or|ress)\", \"cartoon\", \"riddle\", \"joke\"\n",
      "            \"album\"])\n",
      "#4 - family/relationships\n",
      "worder.add([\"love\", \"girl\", \"boy\", \"relationship\",\n",
      "            \"women\", \"date\", \"(boy|girl)friend\", \"marri\",\n",
      "            \"wife\", \"husband\", \"family\", \"dating\", \"sex\",\n",
      "            \" friend\", \"roman(ce|tic)\"\n",
      "            ])\n",
      "#5 - education and reference\n",
      "worder.add([\"school\", \"college\", \"study\", \"english\", \"word\",\n",
      "            \"history\", \"educat\", \"teach\", \"book\", \"spanish\",\n",
      "            \"university\", \"grade\", \"exam\", \"learn\"])\n",
      "#6 - Health\n",
      "worder.add([\"pain\", \"cold\", \"body\", \"surgery\", \"blood\",\n",
      "            \"weight\", \"health\", \"smok(es|ing)\", \"symptoms\",\n",
      "            \"cure\", \"diet\", \"treatment\", \"medic\", \"penis\",\n",
      "            \"vomit\", \"acne\", \"\\d+mg\", \"itching\", \"teeth\",\n",
      "            \"materbat\"])\n",
      "#7 - Science&Mathematics\n",
      "worder.add([\"earth\", \"world\", \"theory\", \"universe\", \"point\",\n",
      "            \"planet\", \"moon\", \"science\", \"math\", \"atom\", \"stars\",\n",
      "            \"\\d+[/*^+-]\\d+\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "def get_terms(t):\n",
      "    \"\"\"\n",
      "    This is used to get the relevant items out of text. \n",
      "    \"\"\"\n",
      "    tokens = nltk.word_tokenize(t)\n",
      "    return [w.lower() for w in tokens if len(w)>3 and (w not in stopwords)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def category_term_scorer1(sample_list):\n",
      "    \"\"\"\n",
      "    takes a list of tuples in format (category,text) and creates scores for each term\n",
      "    for its relevance to each category\n",
      "    \"\"\"\n",
      "    \n",
      "    categories = [str(x) for x in range(1,8)]\n",
      "    idfs = tfidf_class.get_cat_idfs(sample_list, get_terms, categories)\n",
      "    terms = set([t for s in sample_list for t in get_terms(s[1])])\n",
      "    \n",
      "    scores={}\n",
      "    for t in terms:\n",
      "        t_score = {}\n",
      "        for c in categories:\n",
      "            if t in idfs[c]:\n",
      "                t_score[c] = idfs[c][t][1]\n",
      "            else:\n",
      "                others = [cat[t][1] for cat in idfs if t in cat]\n",
      "                t_score[c] = -(sum(others)/(len(others)+1))\n",
      "        scores[t]=t_score\n",
      "    \n",
      "    return scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "termscore1 = term_scoring.TermScoreClassiffier(scorer=category_term_scorer1, key=\"termscore1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor = util.FeatureExtractor()\n",
      "extractor.add_extractor(worder)\n",
      "extractor.add_extractor(termscore1, trained=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.classify.NaiveBayesClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.test(sample_sets, confusion=True, folds=10, classifier=classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "**************************\n",
        "Run 0\n",
        "**************************\n",
        "test 0 - 46.097%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      4      7      3      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <14.5%>  5.2%   1.9%   1.9%   1.9%   4.5%   2.6% |\n",
        "2 |   2.6%  <9.7%>  0.4%      .   1.1%   2.6%   1.1% |\n",
        "4 |   3.0%      .  <7.8%>     .   0.4%      .   0.4% |\n",
        "7 |   2.6%   0.4%      .  <4.1%>  1.5%   1.5%   1.5% |\n",
        "3 |   3.3%      .   0.7%   1.1%  <4.1%>  0.7%   0.4% |\n",
        "5 |   3.3%   0.4%      .   1.5%   0.7%  <3.3%>  0.7% |\n",
        "6 |   2.6%   0.7%   0.4%      .      .   0.4%  <2.6%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 1 - 50.929%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      3      2      4      6      5      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 |  <9.3%>  2.2%   2.2%   2.2%   3.3%   1.9%   3.0% |\n",
        "3 |   4.8%  <7.8%>  1.1%   1.1%   0.4%   1.5%   0.7% |\n",
        "2 |   1.1%   0.7% <10.4%>     .   0.7%   0.7%   0.4% |\n",
        "4 |   3.3%      .   0.4%  <9.3%>  0.7%      .   0.4% |\n",
        "6 |   4.1%      .      .   0.4%  <8.2%>  0.4%   0.4% |\n",
        "5 |   2.2%      .   0.4%   0.7%   1.5%  <3.0%>  0.7% |\n",
        "7 |   2.6%   0.7%   0.7%      .      .   1.1%  <3.0%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 49.071%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      5      7      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <13.8%>  2.6%   1.5%   2.2%   4.5%   4.1%   2.2% |\n",
        "2 |   5.2%  <8.6%>  0.7%      .   0.7%      .   0.7% |\n",
        "3 |   2.2%   0.7%  <8.6%>  1.1%   1.1%   0.7%   0.4% |\n",
        "4 |   1.9%      .   0.4%  <8.2%>     .      .   0.7% |\n",
        "5 |   2.2%   1.5%   0.7%   0.7%  <3.7%>  0.7%   0.7% |\n",
        "7 |   2.6%   0.7%   0.7%      .   1.5%  <4.1%>  0.7% |\n",
        "6 |   2.2%      .      .   0.7%   0.4%   0.7%  <2.2%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 3 - 49.071%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      7      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <10.0%>  3.7%   0.7%   2.6%   2.2%   3.0%   3.7% |\n",
        "2 |   4.1% <14.9%>  1.1%      .      .   0.7%      . |\n",
        "3 |   2.6%   1.5%  <8.6%>  2.2%   0.4%   0.4%   1.5% |\n",
        "4 |   3.3%   0.4%   1.5%  <8.6%>  0.4%      .   0.4% |\n",
        "7 |   2.2%   1.1%   0.7%   0.4%  <3.7%>  1.5%   1.1% |\n",
        "5 |   2.2%   0.7%      .      .   1.1%  <1.1%>  0.4% |\n",
        "6 |   1.9%      .      .   0.4%      .   0.7%  <2.2%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-26-f9538119c54c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/paul/Programming/f2014/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, samples, folds, classifier, num_tests, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Run {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"**************************\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[0mfold_test_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/f2014/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mfold_test_extractor\u001b[1;34m(feature_extractor, samples, folds, classifier, confusion, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_sets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0mfolds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/f2014/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrained_extractors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/f2014/nlp2014_kaggle/term_scoring.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You must train the scorer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/tokenize/__init__.pyc\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdesigned\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwork\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msentence\u001b[0m \u001b[0mat\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \"\"\"\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_word_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/tokenize/treebank.pyc\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m#parens, brackets, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[\\]\\[\\(\\)\\{\\}\\<\\>]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr' \\g<0> '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr' -- '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(*key)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;31m# invalid expression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/sre_compile.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[1;31m# print code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/sre_compile.pyc\u001b[0m in \u001b[0;36m_code\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;31m# compile info block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[0m_compile_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[1;31m# compile the pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/sre_compile.pyc\u001b[0m in \u001b[0;36m_compile_info\u001b[1;34m(code, pattern, flags)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# don't store first entry\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcharset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         \u001b[0m_compile_charset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m     \u001b[0mcode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mskip\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mskip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/sre_compile.pyc\u001b[0m in \u001b[0;36m_compile_charset\u001b[1;34m(charset, flags, code, fixup)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfixup\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mfixup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_identityfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_optimize_charset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m         \u001b[0memit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOPCODES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNEGATE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/sre_compile.pyc\u001b[0m in \u001b[0;36m_optimize_charset\u001b[1;34m(charset, fixup)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0moutappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mLITERAL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                 \u001b[0mcharmap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfixup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mRANGE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mav\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mav\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/sre_compile.pyc\u001b[0m in \u001b[0;36m_identityfunction\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mMAXCODE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0xFFFFFFFFL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_identityfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors = extractor.show_errors(sample_sets, classifier=classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for e in errors:\n",
      "    if e[1]==\"3\":\n",
      "        print e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.test_extractors(sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extractor: wordsearcher\n",
        "test 0 - 50.056%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 1 - 54.394%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 52.444%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Extractor: TermScoreClassifier\n",
        "test 0 - 61.402%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 1 - 63.181%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 63.333%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_features = util.make_feature(extractor, final_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.train_extractors(sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = util.make_classifier(extractor, sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.show_most_informative_features(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "               has(love) = 1                   4 : 2      =     35.8 : 1.0\n",
        "               has(pain) = 1                   6 : 1      =     34.1 : 1.0\n",
        "                has(sex) = 1                   4 : 2      =     33.5 : 1.0\n",
        "              has(music) = 1                   3 : 1      =     30.9 : 1.0\n",
        "               has(girl) = 1                   4 : 7      =     28.6 : 1.0\n",
        "               has(song) = 1                   3 : 1      =     26.8 : 1.0\n",
        "       has(relationship) = 1                   4 : 1      =     25.2 : 1.0\n",
        "              has(movie) = 1                   3 : 4      =     22.5 : 1.0\n",
        "            has(college) = 1                   5 : 2      =     20.4 : 1.0\n",
        "            has( friend) = 1                   4 : 5      =     20.0 : 1.0\n",
        "                has(boy) = 1                   4 : 5      =     19.5 : 1.0\n",
        "              has(medic) = 1                   6 : 1      =     19.1 : 1.0\n",
        "   has((boy|girl)friend) = 1                   4 : 6      =     19.0 : 1.0\n",
        "           has(internet) = 1                   2 : 3      =     18.8 : 1.0\n",
        "               has(rock) = 1                   3 : 1      =     18.3 : 1.0\n",
        "              has(study) = 1                   5 : 1      =     17.8 : 1.0\n",
        "            has(program) = 1                   2 : 3      =     17.0 : 1.0\n",
        "              has(marri) = 1                   4 : 1      =     16.7 : 1.0\n",
        "           has(software) = 1                   2 : 1      =     16.6 : 1.0\n",
        "              has(blood) = 1                   6 : 1      =     16.5 : 1.0\n",
        "             has(school) = 1                   5 : 2      =     16.0 : 1.0\n",
        "                has(web) = 1                   2 : 6      =     15.9 : 1.0\n",
        "               has(cold) = 1                   6 : 3      =     15.7 : 1.0\n",
        "               has(math) = 1                   7 : 1      =     15.6 : 1.0\n",
        "       has(smok(es|ing)) = 1                   6 : 1      =     14.3 : 1.0\n",
        "              has(grade) = 1                   5 : 1      =     13.6 : 1.0\n",
        "               has(moon) = 1                   7 : 1      =     13.5 : 1.0\n",
        "            has(windows) = 1                   2 : 5      =     12.8 : 1.0\n",
        "            has(episode) = 1                   3 : 1      =     12.0 : 1.0\n",
        "           has(magazine) = 1                   3 : 1      =     12.0 : 1.0\n",
        "            has(english) = 1                   5 : 2      =     11.8 : 1.0\n",
        "              has(teach) = 1                   5 : 2      =     11.8 : 1.0\n",
        "            has(science) = 1                   7 : 1      =     11.4 : 1.0\n",
        "             has(weight) = 1                   6 : 1      =     11.2 : 1.0\n",
        "           has(wireless) = 1                   2 : 1      =     10.7 : 1.0\n",
        "              has(women) = 1                   4 : 5      =     10.6 : 1.0\n",
        "               has(wife) = 1                   4 : 1      =     10.2 : 1.0\n",
        "             has(health) = 1                   6 : 1      =      9.9 : 1.0\n",
        "              has(earth) = 1                   7 : 4      =      9.9 : 1.0\n",
        "             has(riddle) = 1                   3 : 1      =      9.5 : 1.0\n",
        "            has(spanish) = 1                   5 : 1      =      9.4 : 1.0\n",
        "               has(show) = 1                   3 : 6      =      9.4 : 1.0\n",
        "               has(date) = 1                   4 : 3      =      9.1 : 1.0\n",
        "            has(e-?mail) = 1                   2 : 3      =      8.8 : 1.0\n",
        "           has(download) = 1                   2 : 1      =      8.5 : 1.0\n",
        "               has(cure) = 1                   6 : 2      =      8.5 : 1.0\n",
        "              has(point) = 1                   7 : 3      =      8.2 : 1.0\n",
        "             has(educat) = 1                   5 : 1      =      8.2 : 1.0\n",
        "           has(favorite) = 1                   3 : 1      =      8.1 : 1.0\n",
        "               has(comp) = 1                   2 : 4      =      7.6 : 1.0\n",
        "            has(website) = 1                   2 : 7      =      7.4 : 1.0\n",
        "            has(history) = 1                   5 : 3      =      7.2 : 1.0\n",
        "             has(theory) = 1                   7 : 3      =      7.1 : 1.0\n",
        "           has(universe) = 1                   7 : 3      =      7.1 : 1.0\n",
        "             has(planet) = 1                   7 : 2      =      6.7 : 1.0\n",
        "             has(family) = 1                   4 : 1      =      6.6 : 1.0\n",
        "              has(penis) = 1                   6 : 3      =      6.4 : 1.0\n",
        "          has(treatment) = 1                   6 : 7      =      6.0 : 1.0\n",
        "               has(body) = 1                   6 : 7      =      5.7 : 1.0\n",
        "               has(word) = 1                   5 : 1      =      5.1 : 1.0\n",
        "               has(book) = 1                   5 : 3      =      5.0 : 1.0\n",
        "            has(cartoon) = 1                   3 : 1      =      4.9 : 1.0\n",
        "               has(diet) = 1                   6 : 7      =      4.6 : 1.0\n",
        "               has(exam) = 1                   2 : 1      =      4.4 : 1.0\n",
        "              has(stars) = 1                   7 : 2      =      4.3 : 1.0\n",
        "            has(husband) = 1                   4 : 1      =      4.2 : 1.0\n",
        "              has(first) = 1                   3 : 1      =      4.1 : 1.0\n",
        "       has(act(or|ress)) = 1                   3 : 1      =      4.0 : 1.0\n",
        "             has(dating) = 1                   4 : 3      =      4.0 : 1.0\n",
        "              has(world) = 1                   7 : 6      =      4.0 : 1.0\n",
        "      has(\\d+(mb|kb|gb)) = 1                   2 : 3      =      3.9 : 1.0\n",
        "               has(atom) = 1                   7 : 3      =      3.8 : 1.0\n",
        "      has(\\d+[/*^+-]\\d+) = 1                   2 : 4      =      3.8 : 1.0\n",
        "             has(series) = 1                   3 : 2      =      3.8 : 1.0\n",
        "              has(learn) = 1                   5 : 1      =      3.6 : 1.0\n",
        "             has(singer) = 1                   3 : 5      =      3.4 : 1.0\n",
        "      has(roman(ce|tic)) = 1                   4 : 3      =      2.6 : 1.0\n",
        "            has(itching) = 1                   6 : 4      =      2.5 : 1.0\n",
        "               has(acne) = 1                   6 : 4      =      2.5 : 1.0\n",
        "               has(html) = 1                   2 : 3      =      2.0 : 1.0\n",
        "               has(love) = 0                   7 : 4      =      1.2 : 1.0\n",
        "               has(girl) = 0                   2 : 4      =      1.2 : 1.0\n",
        "               has(comp) = 0                   4 : 2      =      1.2 : 1.0\n",
        "   has((boy|girl)friend) = 0                   2 : 4      =      1.1 : 1.0\n",
        "            has( friend) = 0                   7 : 4      =      1.1 : 1.0\n",
        "                has(boy) = 0                   2 : 4      =      1.1 : 1.0\n",
        "                has(sex) = 0                   7 : 4      =      1.1 : 1.0\n",
        "                has(web) = 0                   6 : 2      =      1.1 : 1.0\n",
        "              has(movie) = 0                   5 : 3      =      1.1 : 1.0\n",
        "               has(song) = 0                   1 : 3      =      1.1 : 1.0\n",
        "             has(school) = 0                   1 : 5      =      1.1 : 1.0\n",
        "       has(relationship) = 0                   1 : 4      =      1.1 : 1.0\n",
        "            has(windows) = 0                   1 : 2      =      1.1 : 1.0\n",
        "              has(marri) = 0                   2 : 4      =      1.1 : 1.0\n",
        "            has(college) = 0                   3 : 5      =      1.1 : 1.0\n",
        "           has(internet) = 0                   7 : 2      =      1.1 : 1.0\n",
        "               has(pain) = 0                   3 : 6      =      1.1 : 1.0\n",
        "              has(women) = 0                   2 : 4      =      1.1 : 1.0\n",
        "               has(word) = 0                   4 : 5      =      1.1 : 1.0\n",
        "              has(medic) = 0                   2 : 6      =      1.1 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = util.make_submission(cl, final_features, writeto=\"submission17WSB.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    }
   ],
   "metadata": {}
  }
 ]
}