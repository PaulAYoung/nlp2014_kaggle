{
 "metadata": {
  "name": "",
  "signature": "sha256:6f6ffdda672f2cbb1cfb96e2b617352b19a044afefc9fcda9c914d3f4cb5bd0f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import random\n",
      "from os import path\n",
      "\n",
      "import nltk\n",
      "\n",
      "import testing_util as util\n",
      "import term_scoring\n",
      "from testing_util import sample_sets, final_sets\n",
      "\n",
      "import tfidf_class"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feature_num_tokens(text):\n",
      "    return {\"num_tokens\": len(nltk.word_tokenize(text))/10}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feature_avg_len_word(text):\n",
      "    tokens = nltk.word_tokenize(text)\n",
      "    return {\"word_len\": sum([len(w) for w in tokens])/len(tokens)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "stemmer = nltk.PorterStemmer()\n",
      "\n",
      "def get_terms(t):\n",
      "    \"\"\"\n",
      "    This is used to get the relevant items out of text. \n",
      "    \"\"\"\n",
      "    tokens = nltk.word_tokenize(t)\n",
      "    return [stemmer.stem(w.lower()) for w in tokens if len(w)>3 and (w not in stopwords)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_bigrams(t):\n",
      "    \"\"\"\n",
      "    This is used to get the relevant items out of text. \n",
      "    \"\"\"\n",
      "    tokens = nltk.word_tokenize(t)\n",
      "    tokens = [stemmer.stem(w.lower()) for w in tokens if len(w)>3 and (w not in stopwords)]\n",
      "    \n",
      "    return nltk.bigrams(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def category_term_scorer1(sample_list):\n",
      "    \"\"\"\n",
      "    takes a list of tuples in format (category,text) and creates scores for each term\n",
      "    for its relevance to each category\n",
      "    \"\"\"\n",
      "    categories = {}\n",
      "    \n",
      "    for c,s in sample_list:\n",
      "        if c not in categories:\n",
      "            categories[c]=[]\n",
      "        for w in get_terms(s):\n",
      "            categories[c].append(w)\n",
      "    \n",
      "    fd_all = nltk.FreqDist([w for wl in categories.values() for w in wl])\n",
      "    \n",
      "    fd_categories = {c:nltk.FreqDist(v) for c,v in categories.iteritems()}\n",
      "    \n",
      "    term_scores = {}\n",
      "    for term in fd_all.iterkeys():\n",
      "        if fd_all[term] < 5:\n",
      "            continue\n",
      "        d = {}\n",
      "        for c,fd in fd_categories.iteritems():\n",
      "            d[c]= fd[term]/(1+fd_all[term]-fd[term])\n",
      "        term_scores[term]=d\n",
      "    \n",
      "    return term_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def category_term_scorer2(sample_list):\n",
      "    \"\"\"\n",
      "    takes a list of tuples in format (category,text) and creates scores for each term\n",
      "    for its relevance to each category\n",
      "    \"\"\"\n",
      "    categories = {}\n",
      "    \n",
      "    for c,s in sample_list:\n",
      "        if c not in categories:\n",
      "            categories[c]=[]\n",
      "        for w in get_bigrams(s):\n",
      "            categories[c].append(w)\n",
      "    \n",
      "    fd_all = nltk.FreqDist([w for wl in categories.values() for w in wl])\n",
      "    \n",
      "    fd_categories = {c:nltk.FreqDist(v) for c,v in categories.iteritems()}\n",
      "    \n",
      "    term_scores = {}\n",
      "    for term in fd_all.iterkeys():\n",
      "        if fd_all[term] < 5:\n",
      "            continue\n",
      "        d = {}\n",
      "        for c,fd in fd_categories.iteritems():\n",
      "            d[c]= fd[term]/(1+fd_all[term]-fd[term])\n",
      "        term_scores[term]=d\n",
      "    \n",
      "    return term_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "termscore1 = term_scoring.TermScoreClassiffier(scorer=category_term_scorer1, key=\"termscore\", tokenizer=get_terms)\n",
      "termscore2 = term_scoring.TermScoreClassiffier(scorer=category_term_scorer2, key=\"bigramscore\", tokenizer=get_bigrams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf_checker = tfidf_class.TfidfRater(get_terms, nterms=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor = util.FeatureExtractor()\n",
      "extractor.add_extractor(feature_num_tokens)\n",
      "extractor.add_extractor(feature_avg_len_word)\n",
      "extractor.add_extractor(termscore1, trained=True)\n",
      "extractor.add_extractor(termscore2, trained=True)\n",
      "extractor.add_extractor(tfidf_checker, trained=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.test(sample_sets, folds=10, confusion=True, classifier=nltk.classify.NaiveBayesClassifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "**************************\n",
        "Run 0\n",
        "**************************\n",
        "test 0 - 57.993%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      6      5      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <13.4%>  3.7%      .   1.1%   0.7%   1.1%      . |\n",
        "2 |   4.1% <13.4%>  0.4%      .      .   0.4%   0.7% |\n",
        "3 |   5.9%   0.4%  <9.3%>  1.1%      .      .      . |\n",
        "4 |   3.7%      .      . <13.0%>     .      .      . |\n",
        "6 |   3.7%   1.1%      .   1.1%  <3.7%>     .      . |\n",
        "5 |   3.0%   0.4%   0.7%      .   0.4%  <2.2%>  2.2% |\n",
        "7 |   5.2%      .   0.4%      .   0.4%      .  <3.0%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 1 - 54.647%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      7      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <19.0%>  3.0%   0.7%   2.6%      .   1.1%   0.7% |\n",
        "2 |   4.1% <11.5%>  1.1%      .      .   0.4%      . |\n",
        "3 |   5.2%   0.4%  <7.8%>  0.7%      .      .      . |\n",
        "4 |   4.5%   0.4%      .  <7.1%>     .      .      . |\n",
        "7 |   4.5%   0.7%   0.4%      .  <3.3%>  0.7%   0.7% |\n",
        "5 |   5.2%   0.4%   0.4%   1.1%   0.4%  <2.6%>     . |\n",
        "6 |   4.5%      .      .   1.1%      .   0.4%  <3.3%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 60.967%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      4      3      7      2      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <23.4%>  1.5%   1.1%      .   4.5%   0.4%      . |\n",
        "4 |   3.7% <10.4%>  0.7%      .      .      .   0.4% |\n",
        "3 |   5.2%      .  <6.7%>     .   0.4%      .   0.4% |\n",
        "7 |   5.9%      .   0.4%  <4.5%>  0.4%   0.7%   0.4% |\n",
        "2 |   1.1%      .   0.4%      . <10.0%>     .   0.4% |\n",
        "5 |   1.9%   0.7%      .   1.1%   1.1%  <3.3%>  0.4% |\n",
        "6 |   4.8%   1.1%      .      .      .      .  <2.6%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 3 - 57.993%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      7      6      5 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <21.2%>  1.1%   0.4%   3.3%      .   1.1%   0.4% |\n",
        "2 |   3.7% <12.6%>  0.4%      .   1.1%      .   0.4% |\n",
        "3 |   5.9%   0.4%  <8.6%>  1.1%      .      .   0.4% |\n",
        "4 |   3.7%      .      .  <7.8%>     .      .      . |\n",
        "7 |   6.3%   0.4%   0.4%      .  <2.2%>     .   0.4% |\n",
        "6 |   4.1%      .      .   1.1%      .  <3.0%>  0.7% |\n",
        "5 |   4.1%      .      .      .   1.1%      .  <2.6%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 4 - 57.621%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      4      3      6      5      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <21.9%>  4.1%   1.9%   1.1%   0.4%   1.1%   1.1% |\n",
        "2 |   5.2% <13.8%>     .      .      .   0.4%   0.4% |\n",
        "4 |   3.7%      . <10.0%>  0.7%      .      .   0.4% |\n",
        "3 |   5.6%      .   1.1%  <4.8%>     .      .      . |\n",
        "6 |   3.3%      .   0.4%   0.4%  <3.3%>     .   1.5% |\n",
        "5 |   3.3%   0.4%      .   1.1%      .  <2.2%>  1.1% |\n",
        "7 |   2.2%   0.4%      .   0.4%   0.7%      .  <1.5%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 5 - 54.647%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      3      2      4      6      7      5 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <20.1%>  1.1%   5.2%   4.5%   0.4%   1.1%   1.1% |\n",
        "3 |   6.3%  <5.9%>  1.1%   0.7%      .   0.7%      . |\n",
        "2 |   3.0%   1.1% <10.0%>     .      .      .      . |\n",
        "4 |   2.2%      .   0.4%  <8.9%>     .      .      . |\n",
        "6 |   3.0%   0.4%   0.4%   0.7%  <6.7%>     .   0.4% |\n",
        "7 |   3.3%      .   0.7%      .      .  <2.6%>  1.1% |\n",
        "5 |   4.8%      .   1.1%      .      .   0.4%  <0.4%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 6 - 55.019%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      7      4      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <17.5%>  4.5%   1.1%      .   1.5%   0.4%   0.4% |\n",
        "2 |   4.8% <14.1%>  0.4%      .      .   0.4%      . |\n",
        "3 |   7.1%   0.7%  <8.2%>     .   1.1%      .   0.4% |\n",
        "7 |   6.3%   0.4%   0.7%  <2.6%>     .   1.1%   0.4% |\n",
        "4 |   3.3%      .      .   0.4%  <6.7%>     .      . |\n",
        "5 |   4.1%   1.9%   0.4%   1.1%      .  <2.6%>     . |\n",
        "6 |   1.5%      .      .      .   0.7%      .  <3.3%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 7 - 60.223%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      5      7      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <22.3%>  4.8%   0.4%   2.6%   0.4%   1.9%   0.4% |\n",
        "2 |   4.5% <11.5%>  0.7%      .      .      .      . |\n",
        "3 |   3.3%   0.7%  <7.1%>  0.7%   0.4%   0.7%   0.4% |\n",
        "4 |   1.5%   0.4%      .  <9.7%>     .      .   0.4% |\n",
        "5 |   3.3%   1.1%   0.4%      .  <4.5%>  1.5%      . |\n",
        "7 |   5.2%      .   1.1%      .   0.4%  <3.7%>  0.4% |\n",
        "6 |   1.9%      .   0.4%      .      .      .  <1.5%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 8 - 55.762%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      3      2      4      6      5      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <20.1%>  1.9%   2.2%   2.6%   0.7%   0.4%   0.4% |\n",
        "3 |   7.8%  <6.3%>  1.9%   1.1%      .      .   0.4% |\n",
        "2 |   3.7%      . <11.5%>     .   0.4%      .      . |\n",
        "4 |   3.0%   0.7%      .  <9.3%>     .      .      . |\n",
        "6 |   5.6%      .   0.4%      .  <4.5%>     .   0.4% |\n",
        "5 |   3.7%   0.4%   1.1%      .   0.4%  <1.9%>     . |\n",
        "7 |   3.7%   0.4%   0.4%   0.4%   0.4%      .  <2.2%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 9 - 56.318%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      5      4      6      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <18.4%>  3.2%   1.8%   0.7%   2.9%   0.7%   0.4% |\n",
        "2 |   2.5% <13.0%>  0.4%   0.4%      .      .      . |\n",
        "3 |   3.6%   0.7% <10.1%>  0.4%   0.7%      .   0.4% |\n",
        "5 |   4.3%   0.4%   0.7%  <4.7%>  0.7%      .   1.1% |\n",
        "4 |   4.3%   0.4%   1.1%      .  <5.4%>  0.4%      . |\n",
        "6 |   4.3%   0.4%      .      .   0.4%  <4.0%>     . |\n",
        "7 |   4.3%   0.7%   0.7%   0.4%      .   0.4%  <0.7%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = extractor.get_classifier(sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.show_most_informative_features(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "               termscore = '4'                 4 : 2      =    224.9 : 1.0\n",
        "               termscore = '6'                 6 : 2      =    143.0 : 1.0\n",
        "               termscore = '5'                 5 : 2      =     69.6 : 1.0\n",
        "               termscore = '7'                 7 : 2      =     65.3 : 1.0\n",
        "               termscore = '3'                 3 : 6      =     52.4 : 1.0\n",
        "             has(window) = 1                   2 : 1      =     42.3 : 1.0\n",
        "             bigramscore = '4'                 4 : 2      =     33.5 : 1.0\n",
        "               has(pain) = 1                   6 : 1      =     31.9 : 1.0\n",
        "             has(comput) = 1                   2 : 4      =     29.8 : 1.0\n",
        "              has(music) = 1                   3 : 1      =     29.6 : 1.0\n",
        "             bigramscore = '2'                 2 : 4      =     27.3 : 1.0\n",
        "               termscore = '2'                 2 : 4      =     27.3 : 1.0\n",
        "               has(song) = 1                   3 : 1      =     25.3 : 1.0\n",
        "               has(caus) = 1                   6 : 1      =     25.3 : 1.0\n",
        "               has(girl) = 1                   4 : 7      =     24.9 : 1.0\n",
        "       has(relationship) = 1                   4 : 1      =     24.3 : 1.0\n",
        "             has(togeth) = 1                   4 : 1      =     24.3 : 1.0\n",
        "               has(movi) = 1                   3 : 4      =     22.5 : 1.0\n",
        "              has(studi) = 1                   5 : 1      =     22.0 : 1.0\n",
        "             bigramscore = '5'                 5 : 1      =     21.8 : 1.0\n",
        "          has(boyfriend) = 1                   4 : 3      =     21.4 : 1.0\n",
        "         has(girlfriend) = 1                   4 : 1      =     21.4 : 1.0\n",
        "              has(medic) = 1                   6 : 1      =     20.9 : 1.0\n",
        "             has(colleg) = 1                   5 : 2      =     20.4 : 1.0\n",
        "            has(marriag) = 1                   4 : 1      =     19.9 : 1.0\n",
        "             has(friend) = 1                   4 : 5      =     19.5 : 1.0\n",
        "           has(internet) = 1                   2 : 3      =     18.8 : 1.0\n",
        "               has(bodi) = 1                   6 : 1      =     18.7 : 1.0\n",
        "             has(weight) = 1                   6 : 1      =     18.7 : 1.0\n",
        "              has(cheat) = 1                   4 : 1      =     18.4 : 1.0\n",
        "              has(yahoo) = 1                   2 : 5      =     18.1 : 1.0\n",
        "               has(feel) = 1                   4 : 2      =     17.9 : 1.0\n",
        "                has(use) = 1                   2 : 4      =     17.6 : 1.0\n",
        "             has(school) = 1                   5 : 1      =     17.5 : 1.0\n",
        "            has(softwar) = 1                   2 : 1      =     16.6 : 1.0\n",
        "              has(blood) = 1                   6 : 1      =     16.5 : 1.0\n",
        "              has(smoke) = 1                   6 : 1      =     16.5 : 1.0\n",
        "               has(love) = 1                   4 : 6      =     16.2 : 1.0\n",
        "               has(rock) = 1                   3 : 1      =     15.8 : 1.0\n",
        "            has(program) = 1                   2 : 3      =     15.2 : 1.0\n",
        "             has(realli) = 1                   4 : 5      =     14.3 : 1.0\n",
        "              has(woman) = 1                   4 : 1      =     13.7 : 1.0\n",
        "              has(marri) = 1                   4 : 1      =     13.7 : 1.0\n",
        "               has(keep) = 1                   4 : 3      =     13.6 : 1.0\n",
        "            has(univers) = 1                   7 : 1      =     13.5 : 1.0\n",
        "               has(moon) = 1                   7 : 1      =     13.5 : 1.0\n",
        "             has(instal) = 1                   2 : 1      =     13.2 : 1.0\n",
        "              has(fight) = 1                   6 : 1      =     12.5 : 1.0\n",
        "            has(magazin) = 1                   3 : 1      =     12.0 : 1.0\n",
        "             has(episod) = 1                   3 : 1      =     12.0 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_features = util.make_feature(extractor, final_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = util.make_submission(cl, final_features, writeto=\"submission27.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}