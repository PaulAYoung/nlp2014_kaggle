{
 "metadata": {
  "name": "",
  "signature": "sha256:a96b254f6d62c618c3a3fd03e3183f7168fbec21ea72a8e6ba7e8060a5499eaa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import random\n",
      "from os import path\n",
      "\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_train = path.join(path.curdir, \"train.txt\")\n",
      "path_final_testing = path.join(path.curdir, \"test.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def file_to_sets(fname, ignore_header=True):\n",
      "    \"\"\"\n",
      "    Takes a file where each line is in the format \"category,text\" and turns it into a list of tuples\n",
      "    in format \"(category, text)\"\n",
      "    \"\"\"\n",
      "    \n",
      "    f = open(fname, 'r')\n",
      "    \n",
      "    if ignore_header:\n",
      "        # This skips the first line of the file\n",
      "        next(f)\n",
      "    \n",
      "    out = []\n",
      "    for line in f:\n",
      "        # iterate over lines, use simple regex to separate the category from text\n",
      "        out.append(re.match(r\"(\\d+),(.+$)\", line).groups())\n",
      "    \n",
      "    f.close()\n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_sets = file_to_sets(path_train, ignore_header=False)\n",
      "final_sets = file_to_sets(path_final_testing, ignore_header=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sets(samples, test_fraction=3):\n",
      "    \"\"\"\n",
      "    takes a set of samples, shuffles them, then returns two lists, train_sets and test_sets. \n",
      "    The size of test_sets is len(samples)/test_fraction, train_sets is the remainder. \n",
      "    \"\"\"\n",
      "    \n",
      "    # don't shuffle the sample list as that will affect the list passed in\n",
      "    l = samples[:]\n",
      "    random.shuffle(l)\n",
      "    \n",
      "    test_size = int(len(l)/test_fraction)\n",
      "    test_sets = l[0:test_size]\n",
      "    train_sets = l[test_size:]\n",
      "    \n",
      "    return train_sets, test_sets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_folds(samples, folds=3):\n",
      "    \"\"\"\n",
      "    Returns of list of folds from samples\n",
      "    \"\"\"\n",
      "    \n",
      "    # don't shuffle the sample list as that will affect the list passed in\n",
      "    l = samples[:]\n",
      "    random.shuffle(l)\n",
      "    out = []\n",
      "    chunk_size = int(len(samples)/folds)\n",
      "    sections = range(0, len(samples)+1, chunk_size)\n",
      "    sections[-1]= None\n",
      "    \n",
      "    for i in range(0,len(sections)-1):\n",
      "        out.append(l[sections[i]:sections[i+1]])\n",
      "    \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "def get_terms(t):\n",
      "    tokens = nltk.word_tokenize(t)\n",
      "    return [w for w in tokens if w not in stopwords]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_training_sets (feature_function, items):\n",
      "    # Create the features sets.  Call the function that was passed in.\n",
      "    # For names, key is the name, and value is the gender\n",
      "    featuresets = [(feature_function(key), value) for (key, value) in items]\n",
      "    \n",
      "    # Divided training and testing in half.  Could divide in other proportions instead.\n",
      "    halfsize = int(float(len(featuresets)) / 2.0)\n",
      "    train_set, test_set = featuresets[halfsize:], featuresets[:halfsize]\n",
      "    return train_set, test_set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_classifier(feature_extractor, train, classifier=nltk.classify.NaiveBayesClassifier):\n",
      "    \"\"\"\n",
      "    creates a classifier based on the feature_extractor, trains it with train and\n",
      "    tests it with test\n",
      "    \"\"\"\n",
      "    train_features = [(feature_extractor(text), category) for (category, text) in train]\n",
      "    \n",
      "    cl = classifier.train(train_features)\n",
      "    return cl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fold_test_extractor(feature_extractor, samples, folds=3):\n",
      "    \"\"\"\n",
      "    Tests a feature extractor with a set of sample tuples in format (category, text)\n",
      "\n",
      "    Params:\n",
      "    feature_extractor -- The feature extractor function to use\n",
      "    samples -- the samples to test with\n",
      "    folds -- the number of folds to use in testing\n",
      "    \"\"\"\n",
      "    \n",
      "    features = [(feature_extractor(text), category) for category, text in samples]\n",
      "    folds = get_folds(features, folds)\n",
      "    \n",
      "    for i in range(0, len(folds)):\n",
      "        train = [f for idx, s in enumerate(folds) for f in s if idx !=i]\n",
      "        test = folds[i]\n",
      "        \n",
      "        cl = nltk.NaiveBayesClassifier.train(train)\n",
      "        print \"test {} - {:.3%}\".format(i, nltk.classify.accuracy(cl, test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_submission(classifier, samples, writeto=None):\n",
      "    out = []\n",
      "    for s in samples:\n",
      "        out.append((s[1], classifier.classify(s[0])))\n",
      "    \n",
      "    if writeto:\n",
      "        out_file = open(writeto, 'w')\n",
      "        out_file.write(\"Id,Category\\n\")\n",
      "        for n, c in out:\n",
      "            out_file.write(\"{},{}\\n\".format(n,c))\n",
      "    \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_feature(extractor, samples):\n",
      "    return [(extractor(text), category) for category, text in samples]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FeatureExtractor(object):\n",
      "    \"\"\"A class to make it easy to combine and shuffle around feature extractors\"\"\"\n",
      "    \n",
      "    def __init__(self, extractors=None, name=\"ExtractorCollection\"):\n",
      "        \"\"\"\n",
      "        Takes a list of extractors to use in extracting features. \n",
      "        Extractors should take a piece of text and return a dictionary where the key is\n",
      "        the desired key and the value is the feature value. \n",
      "        \"\"\"\n",
      "        if extractors is None:\n",
      "            extractors = []\n",
      "            \n",
      "        if type(extractors) is not list:\n",
      "            extractors = [extractors]\n",
      "        \n",
      "        self.__name__ = name\n",
      "        self.extractors = extractors\n",
      "        \n",
      "    def __call__(self, text):\n",
      "        features = {}\n",
      "        for e in self.extractors:\n",
      "            f = e(text)\n",
      "            for k, v in f.iteritems():\n",
      "                features[k]=v\n",
      "        \n",
      "        return features\n",
      "    \n",
      "    def add_extractor(self,extractor):\n",
      "        self.extractors.append(extractor)\n",
      "    \n",
      "    def test_extractors(self, samples, folds=3):\n",
      "        \"\"\"\n",
      "        Runs a test of each individual extractor using samples to train and test. \n",
      "        \"\"\"\n",
      "        for e in self.extractors:\n",
      "            print \"Extractor: {}\".format(e.__name__)\n",
      "            fold_test_extractor(e, samples, folds)\n",
      "    \n",
      "    def test(self, samples, folds=3):\n",
      "        fold_test_extractor(self, samples, folds)\n",
      "    \n",
      "    def get_classifier(self, samples, classifier=nltk.classify.NaiveBayesClassifier):\n",
      "        \"\"\"\n",
      "        Creates a classifier based on the extractor, using samples to train and the classifier as the\n",
      "        method.\n",
      "        \"\"\"\n",
      "        return make_classifier(self, samples, classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}