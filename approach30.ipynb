{
 "metadata": {
  "name": "",
  "signature": "sha256:69f7c867c3b2e90372fdd026d547d908112580a717bf00cd6f14a11eabe9be61"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import random\n",
      "from os import path\n",
      "\n",
      "import nltk\n",
      "\n",
      "import testing_util as util\n",
      "import term_scoring\n",
      "from testing_util import sample_sets, final_sets\n",
      "\n",
      "import tfidf_class"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feature_num_tokens(text):\n",
      "    return {\"num_tokens\": len(nltk.word_tokenize(text))/10}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feature_avg_len_word(text):\n",
      "    tokens = nltk.word_tokenize(text)\n",
      "    return {\"word_len\": sum([len(w) for w in tokens])/len(tokens)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "stemmer = nltk.PorterStemmer()\n",
      "\n",
      "def get_terms(t):\n",
      "    \"\"\"\n",
      "    This is used to get the relevant items out of text. \n",
      "    \"\"\"\n",
      "    tokens = nltk.word_tokenize(t)\n",
      "    return [w.lower() for w in tokens if len(w)>3 and (w not in stopwords)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def category_term_scorer1(sample_list):\n",
      "    \"\"\"\n",
      "    takes a list of tuples in format (category,text) and creates scores for each term\n",
      "    for its relevance to each category\n",
      "    \"\"\"\n",
      "    \n",
      "    categories = [str(x) for x in range(1,8)]\n",
      "    idfs = tfidf_class.get_cat_idfs(sample_list, get_terms, categories)\n",
      "    terms = set([t for s in sample_list for t in get_terms(s[1])])\n",
      "    \n",
      "    scores={}\n",
      "    for t in terms:\n",
      "        t_score = {}\n",
      "        for c in categories:\n",
      "            if t in idfs[c]:\n",
      "                t_score[c] = idfs[c][t][1]\n",
      "            else:\n",
      "                others = [cat[t][1] for cat in idfs if t in cat]\n",
      "                t_score[c] = -(sum(others)/(len(others)+1))\n",
      "        scores[t]=t_score\n",
      "    \n",
      "    return scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def category_term_scorer2(sample_list):\n",
      "    \"\"\"\n",
      "    takes a list of tuples in format (category,text) and creates scores for each term\n",
      "    for its relevance to each category\n",
      "    \"\"\"\n",
      "    categories = {}\n",
      "    \n",
      "    for c,s in sample_list:\n",
      "        if c not in categories:\n",
      "            categories[c]=[]\n",
      "        for w in get_terms(s):\n",
      "            categories[c].append(w)\n",
      "    \n",
      "    fd_all = nltk.FreqDist([w for wl in categories.values() for w in wl])\n",
      "    \n",
      "    fd_categories = {c:nltk.FreqDist(v) for c,v in categories.iteritems()}\n",
      "    \n",
      "    term_scores = {}\n",
      "    for term in fd_all.iterkeys():\n",
      "        if fd_all[term] < 5:\n",
      "            continue\n",
      "        d = {}\n",
      "        for c,fd in fd_categories.iteritems():\n",
      "            d[c]= fd[term]/(1+fd_all[term]-fd[term])\n",
      "        term_scores[term]=d\n",
      "    \n",
      "    return term_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class WordSearcher(object):\n",
      "    def __init__(self, wordlist=None, key=\"\", name=\"wordsearcher\"):\n",
      "        self.wordlist = wordlist if wordlist else []\n",
      "        self.key = key\n",
      "        self.name=name\n",
      "    \n",
      "    def add(self, wordlist):\n",
      "        self.wordlist.extend(wordlist)\n",
      "    \n",
      "    def clear(self):\n",
      "        self.wordlist = []\n",
      "    \n",
      "    def __call__(self, text):\n",
      "        out = {}\n",
      "        for word in self.wordlist:\n",
      "            out[\"{}has({})\".format(self.key, word)] = 1 if re.search(word, text, re.IGNORECASE) else 0\n",
      "        return out\n",
      "\n",
      "worder = WordSearcher()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worder.clear()\n",
      "#1-business\n",
      "worder.add([\"money\", \"credit\", \"business\", \"sell\"])\n",
      "#2-computers\n",
      "worder.add([\"comp\", \"linux\", \"windows\", \"internet\",\n",
      "            \"software\", \"program\", r\"\\d+(mb|kb|gb)\",\n",
      "            \"download\", \"e-?mail\", \"web\", \"laptop\",\n",
      "            \"wireless\", \"website\", \"html\", \"smtp\"])\n",
      "#3 - entertainment\n",
      "worder.add([\"song\", \"movie\", \"music\", \"favorite\",\n",
      "            \"show\", \"first\", \"rock\", \"magazine\",\n",
      "            \"lyric\", \"series\", \"episode\", \"singer\",\n",
      "            \"act(or|ress)\", \"cartoon\", \"riddle\", \"joke\"\n",
      "            \"album\"])\n",
      "#4 - family/relationships\n",
      "worder.add([\"love\", \"girl\", \"boy\", \"relationship\",\n",
      "            \"women\", \"date\", \"(boy|girl)friend\", \"marri\",\n",
      "            \"wife\", \"husband\", \"family\", \"dating\", \"sex\",\n",
      "            \" friend\", \"roman(ce|tic)\"\n",
      "            ])\n",
      "#5 - education and reference\n",
      "worder.add([\"school\", \"college\", \"study\", \"english\", \"word\",\n",
      "            \"history\", \"educat\", \"teach\", \"book\", \"spanish\",\n",
      "            \"university\", \"grade\", \"exam\", \"learn\"])\n",
      "#6 - Health\n",
      "worder.add([\"pain\", \"cold\", \"body\", \"surgery\", \"blood\",\n",
      "            \"weight\", \"health\", \"smok(es|ing)\", \"symptoms\",\n",
      "            \"cure\", \"diet\", \"treatment\", \"medic\", \"penis\",\n",
      "            \"vomit\", \"acne\", \"\\d+mg\", \"itching\", \"teeth\",\n",
      "            \"materbat\"])\n",
      "#7 - Science&Mathematics\n",
      "worder.add([\"earth\", \"world\", \"theory\", \"universe\", \"point\",\n",
      "            \"planet\", \"moon\", \"science\", \"math\", \"atom\", \"stars\",\n",
      "            \"\\d+[/*^+-]\\d+\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def notbiz(text):\n",
      "    terms = [\"comp\", \"linux\", \"windows\", \"internet\",\n",
      "            \"software\", \"program\", r\"\\d+(mb|kb|gb)\",\n",
      "            \"download\", \"e-?mail\", \"web\", \"(desk|lap)top\",\n",
      "            \"wireless\", \"website\", \"html\", \"smtp\",\n",
      "            \"song\", \"movie\", \"music\", \"favorite\",\n",
      "            \"show\", \"first\", \"rock\", \"magazine\",\n",
      "            \"lyric\", \"series\", \"episode\", \"singer\",\n",
      "            \"act(or|ress)\", \"cartoon\", \"riddle\", \"joke\"\n",
      "            \"album\", \"love\", \"girl\", \"boy\", \"relationship\",\n",
      "            \"women\", \"date\", \"(boy|girl)friend\", \"marri\",\n",
      "            \"wife\", \"husband\", \"family\", \"dating\", \"sex\",\n",
      "            \" friend\", \"roman(ce|tic)\", \"school\", \"college\",\n",
      "            \"study\", \"english\", \"word\",\n",
      "            \"history\", \"educat\", \"teach\", \"book\", \"spanish\",\n",
      "            \"university\", \"grade\", \"exam\", \"learn\", \n",
      "            \"pain\", \"cold\", \"body\", \"surgery\", \"blood\",\n",
      "            \"weight\", \"health\", \"smok(es|ing)\", \"symptoms\",\n",
      "            \"cure\", \"diet\", \"treatment\", \"medic\", \"penis\",\n",
      "            \"vomit\", \"acne\", \"\\d+mg\", \"itching\", \"teeth\",\n",
      "            \"materbat\", \"earth\", \"world\", \"theory\", \"universe\", \"point\",\n",
      "            \"planet\", \"moon\", \"science\", \"math\", \"atom\", \"stars\",\n",
      "            \"\\d+[/*^+-]\\d+\"]\n",
      "    score = 0\n",
      "    for word in terms:\n",
      "        if re.search(word, text, re.IGNORECASE):\n",
      "            score += 1\n",
      "    if score > 3:\n",
      "        score = 3\n",
      "    return {\"notbiz\":score}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "termscore1 = term_scoring.TermScoreClassiffier(scorer=category_term_scorer1, key=\"termscore1\")\n",
      "termscore2 = term_scoring.TermScoreClassiffier(scorer=category_term_scorer2, key=\"termscore2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor = util.FeatureExtractor()\n",
      "extractor.add_extractor(feature_num_tokens)\n",
      "extractor.add_extractor(feature_avg_len_word)\n",
      "extractor.add_extractor(termscore1, trained=True)\n",
      "extractor.add_extractor(termscore2, trained=True)\n",
      "extractor.add_extractor(worder)\n",
      "extractor.add_extractor(notbiz)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.test(sample_sets, folds=10, confusion=True, classifier=nltk.classify.NaiveBayesClassifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "**************************\n",
        "Run 0\n",
        "**************************\n",
        "test 0 - 51.301%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      7      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <20.4%>  3.0%   2.6%   2.2%      .   0.7%      . |\n",
        "2 |   4.5% <10.4%>  0.7%      .      .      .      . |\n",
        "3 |   4.8%   0.7%  <7.1%>  1.5%      .      .   0.4% |\n",
        "4 |   3.3%   0.7%      .  <8.9%>     .      .      . |\n",
        "7 |   8.6%   1.1%   0.7%   0.4%  <0.7%>  0.7%   0.4% |\n",
        "5 |   3.7%   0.7%   0.4%   1.5%   1.5%  <1.5%>     . |\n",
        "6 |   3.0%      .      .   0.7%      .      .  <2.2%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 1 - 52.045%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      4      3      7      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <17.8%>  3.7%   3.7%   0.7%      .   0.4%   0.4% |\n",
        "2 |   5.9% <13.4%>  0.4%      .      .      .      . |\n",
        "4 |   3.3%   0.7%  <9.3%>     .   0.4%      .   0.4% |\n",
        "3 |   4.8%   1.1%   1.9%  <5.2%>     .      .      . |\n",
        "7 |   4.1%   1.1%      .   0.7%  <2.6%>  0.4%   0.4% |\n",
        "5 |   4.1%   1.1%   1.1%   0.7%   0.4%  <1.5%>     . |\n",
        "6 |   5.6%      .   0.4%      .      .      .  <2.2%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 51.301%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      5      6      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <21.6%>  3.7%   2.6%   1.5%   0.7%   0.4%      . |\n",
        "2 |   4.1% <11.5%>  0.4%      .      .      .      . |\n",
        "3 |   7.1%   1.5%  <4.8%>  1.5%      .      .      . |\n",
        "4 |   5.2%      .   0.4%  <8.2%>     .      .      . |\n",
        "5 |   5.2%   1.5%   0.4%   1.1%  <0.7%>     .      . |\n",
        "6 |   5.2%      .      .   1.1%      .  <2.6%>     . |\n",
        "7 |   3.7%   0.4%   0.7%      .   0.4%      .  <1.9%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-11-d8b82cf49303>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, samples, folds, classifier, num_tests, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Run {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"**************************\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mfold_test_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mfold_test_extractor\u001b[1;34m(feature_extractor, samples, folds, classifier, confusion, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_extractors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_scoring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTermScoreBagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mtrain_extractors\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_extractors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrained_extractors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest_extractors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/term_scoring.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-5-7d9068b2f4b8>\u001b[0m in \u001b[0;36mcategory_term_scorer1\u001b[1;34m(sample_list)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0midfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cat_idfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mterms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_list\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_terms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/tfidf_class.pyc\u001b[0m in \u001b[0;36mget_cat_idfs\u001b[1;34m(samples, termer, categories)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mcat_idf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_idfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtermer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mother_idf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_idfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtermer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/tfidf_class.pyc\u001b[0m in \u001b[0;36mget_idfs\u001b[1;34m(samples, termer)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_idfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtermer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0msample_terms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtermer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mnsamps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0midf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-4-b22997a22a35>\u001b[0m in \u001b[0;36mget_terms\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrelevant\u001b[0m \u001b[0mitems\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/tokenize/__init__.pyc\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdesigned\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwork\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msentence\u001b[0m \u001b[0mat\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \"\"\"\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_word_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/tokenize/treebank.pyc\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"([^' ])('[sS]|'[mM]|'[dD]|') \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"\\1 \\2 \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"([^' ])('ll|'re|'ve|n't|) \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"\\1 \\2 \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"([^' ])('LL|'RE|'VE|N'T|) \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"\\1 \\2 \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(match, template)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;31m# literal replacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_template\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.train_extractors(sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = extractor.get_classifier(sample_sets, retrain=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.show_most_informative_features(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "              termscore2 = '4'                 4 : 2      =    132.8 : 1.0\n",
        "              termscore2 = '6'                 6 : 3      =    106.0 : 1.0\n",
        "              termscore2 = '3'                 3 : 6      =     81.2 : 1.0\n",
        "              termscore2 = '5'                 5 : 2      =     67.1 : 1.0\n",
        "              termscore2 = '7'                 7 : 3      =     58.5 : 1.0\n",
        "              termscore2 = '2'                 2 : 4      =     28.5 : 1.0\n",
        "                  notbiz = 3                   4 : 7      =      6.7 : 1.0\n",
        "              num_tokens = 12                  4 : 1      =      6.5 : 1.0\n",
        "              num_tokens = 10                  2 : 1      =      6.1 : 1.0\n",
        "              num_tokens = 4                   2 : 7      =      5.4 : 1.0\n",
        "              num_tokens = 14                  6 : 1      =      5.3 : 1.0\n",
        "                word_len = 6                   5 : 3      =      5.0 : 1.0\n",
        "                  notbiz = 2                   4 : 7      =      4.1 : 1.0\n",
        "              termscore2 = '1'                 1 : 2      =      3.9 : 1.0\n",
        "                word_len = 5                   7 : 4      =      3.7 : 1.0\n",
        "              num_tokens = 8                   4 : 5      =      3.6 : 1.0\n",
        "              num_tokens = 9                   6 : 7      =      3.2 : 1.0\n",
        "                word_len = 2                   4 : 5      =      3.2 : 1.0\n",
        "              num_tokens = 7                   2 : 5      =      3.1 : 1.0\n",
        "                  notbiz = 0                   1 : 4      =      3.1 : 1.0\n",
        "              num_tokens = 20                  7 : 2      =      3.0 : 1.0\n",
        "              num_tokens = 5                   2 : 6      =      2.7 : 1.0\n",
        "                word_len = 4                   5 : 4      =      2.6 : 1.0\n",
        "              num_tokens = 6                   4 : 1      =      2.6 : 1.0\n",
        "              num_tokens = 11                  6 : 4      =      2.4 : 1.0\n",
        "              num_tokens = 21                  4 : 1      =      2.2 : 1.0\n",
        "              num_tokens = 3                   7 : 5      =      1.9 : 1.0\n",
        "              num_tokens = 15                  4 : 3      =      1.9 : 1.0\n",
        "              num_tokens = 17                  3 : 1      =      1.9 : 1.0\n",
        "              num_tokens = 16                  3 : 1      =      1.9 : 1.0\n",
        "              num_tokens = 13                  5 : 1      =      1.8 : 1.0\n",
        "              num_tokens = 0                   1 : 4      =      1.6 : 1.0\n",
        "                  notbiz = 1                   4 : 1      =      1.6 : 1.0\n",
        "              num_tokens = 1                   3 : 2      =      1.5 : 1.0\n",
        "                word_len = 3                   4 : 7      =      1.5 : 1.0\n",
        "              num_tokens = 2                   5 : 3      =      1.4 : 1.0\n",
        "              num_tokens = 18                  4 : 2      =      1.3 : 1.0\n",
        "              num_tokens = 19                  6 : 7      =      1.1 : 1.0\n",
        "                word_len = 8                   5 : 7      =      1.0 : 1.0\n",
        "              termscore1 = '1'                 1 : 6      =      1.0 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_features = util.make_feature(extractor, final_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = util.make_submission(cl, final_features, writeto=\"submission30.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}