{
 "metadata": {
  "name": "",
  "signature": "sha256:604ca304d9a1d303c841b28873efcad53cfb377b78da87d0b1cd4a026b24016a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import random\n",
      "from os import path\n",
      "\n",
      "import nltk\n",
      "\n",
      "import testing_util as util\n",
      "import term_scoring\n",
      "from testing_util import sample_sets, final_sets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.classify import SklearnClassifier\n",
      "from sklearn.svm import SVC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "def get_terms(t):\n",
      "    \"\"\"\n",
      "    This is used to get the relevant items out of text. \n",
      "    \"\"\"\n",
      "    tokens = nltk.word_tokenize(t)\n",
      "    return [w.lower() for w in tokens if len(w)>3 and (w not in stopwords)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def category_term_scorer(sample_list):\n",
      "    \"\"\"\n",
      "    takes a list of tuples in format (category,text) and creates scores for each term\n",
      "    for its relevance to each category\n",
      "    \"\"\"\n",
      "    categories = {}\n",
      "    \n",
      "    for c,s in sample_list:\n",
      "        if c not in categories:\n",
      "            categories[c]=[]\n",
      "        for w in get_terms(s):\n",
      "            categories[c].append(w)\n",
      "    \n",
      "    fd_all = nltk.FreqDist([w for wl in categories.values() for w in wl])\n",
      "    \n",
      "    fd_categories = {c:nltk.FreqDist(v) for c,v in categories.iteritems()}\n",
      "    \n",
      "    term_scores = {}\n",
      "    for term in fd_all.iterkeys():\n",
      "        if fd_all[term] < 5:\n",
      "            continue\n",
      "        d = {}\n",
      "        for c,fd in fd_categories.iteritems():\n",
      "            d[c]= fd[term]/(1+fd_all[term]-fd[term])\n",
      "        term_scores[term]=d\n",
      "    \n",
      "    return term_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_term_score = term_scoring.TermScoreClassiffier(sample_sets, category_term_scorer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feature_num_tokens(text):\n",
      "    return {\"num_tokens\": len(nltk.word_tokenize(text))/10}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feature_avg_len_word(text):\n",
      "    tokens = nltk.word_tokenize(text)\n",
      "    return {\"word_len\": sum([len(w) for w in tokens])/len(tokens)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor = util.FeatureExtractor()\n",
      "extractor.add_extractor(feature_num_tokens)\n",
      "extractor.add_extractor(feature_avg_len_word)\n",
      "extractor.add_extractor(feature_term_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.test(sample_sets, folds=10, method=SklearnClassifier(SVC(), sparse=False))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "test 0 - 65.428%\n",
        "test 1 - 55.762%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 58.736%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 3 - 63.197%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 4 - 55.390%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 5 - 58.736%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 6 - 62.825%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 7 - 60.595%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 8 - 62.082%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 9 - 59.206%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.test_extractors(sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extractor: feature_num_tokens\n",
        "test 0 - 27.920%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 1 - 28.587%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 28.111%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Extractor: feature_avg_len_word\n",
        "test 0 - 27.253%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 1 - 28.476%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 30.000%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Extractor: TermScoreClassifier\n",
        "test 0 - 61.290%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 1 - 61.513%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test 2 - 57.111%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl=extractor.get_classifier(sample_sets, classifier=SklearnClassifier(SVC(), sparse=False))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_features = util.make_feature(extractor, final_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = util.make_submission(cl, final_features, writeto=\"submission3.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}