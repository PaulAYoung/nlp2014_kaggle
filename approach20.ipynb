{
 "metadata": {
  "name": "",
  "signature": "sha256:680154d1f58c019d8bcbd4e41053413c1dea1d4f23a19bc413f5f84be3bb5fb3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import random\n",
      "from os import path\n",
      "\n",
      "import nltk\n",
      "\n",
      "import testing_util as util\n",
      "import term_scoring\n",
      "from testing_util import sample_sets, final_sets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class WordSearcher(object):\n",
      "    def __init__(self, wordlist=None, key=\"\", name=\"wordsearcher\"):\n",
      "        self.wordlist = wordlist if wordlist else []\n",
      "        self.key = key\n",
      "        self.name=name\n",
      "    \n",
      "    def add(self, wordlist):\n",
      "        self.wordlist.extend(wordlist)\n",
      "    \n",
      "    def clear(self):\n",
      "        self.wordlist = []\n",
      "    \n",
      "    def __call__(self, text):\n",
      "        out = {}\n",
      "        for word in self.wordlist:\n",
      "            out[\"{}has({})\".format(self.key, word)] = 1 if re.search(word, text, re.IGNORECASE) else 0\n",
      "        return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worder = WordSearcher()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worder.clear()\n",
      "#1-business\n",
      "worder.add([\"money\", \"credit\", \"business\", \"sell\"])\n",
      "#2-computers\n",
      "worder.add([\"comp\", \"linux\", \"windows\", \"internet\",\n",
      "            \"software\", \"program\", r\"\\d+(mb|kb|gb)\",\n",
      "            \"download\", \"e-?mail\", \"web\", \"laptop\",\n",
      "            \"wireless\", \"website\", \"html\", \"smtp\"])\n",
      "#3 - entertainment\n",
      "worder.add([\"song\", \"movie\", \"music\", \"favorite\",\n",
      "            \"show\", \"first\", \"rock\", \"magazine\",\n",
      "            \"lyric\", \"series\", \"episode\", \"singer\",\n",
      "            \"act(or|ress)\", \"cartoon\", \"riddle\", \"joke\"\n",
      "            \"album\"])\n",
      "#4 - family/relationships\n",
      "worder.add([\"love\", \"girl\", \"boy\", \"relationship\",\n",
      "            \"women\", \"date\", \"(boy|girl)friend\", \"marri\",\n",
      "            \"wife\", \"husband\", \"family\", \"dating\", \"sex\",\n",
      "            \" friend\", \"roman(ce|tic)\"\n",
      "            ])\n",
      "#5 - education and reference\n",
      "worder.add([\"school\", \"college\", \"study\", \"english\", \"word\",\n",
      "            \"history\", \"educat\", \"teach\", \"book\", \"spanish\",\n",
      "            \"university\", \"grade\", \"exam\", \"learn\"])\n",
      "#6 - Health\n",
      "worder.add([\"pain\", \"cold\", \"body\", \"surgery\", \"blood\",\n",
      "            \"weight\", \"health\", \"smok(es|ing)\", \"symptoms\",\n",
      "            \"cure\", \"diet\", \"treatment\", \"medic\", \"penis\",\n",
      "            \"vomit\", \"acne\", \"\\d+mg\", \"itching\", \"teeth\",\n",
      "            \"materbat\"])\n",
      "#7 - Science&Mathematics\n",
      "worder.add([\"earth\", \"world\", \"theory\", \"universe\", \"point\",\n",
      "            \"planet\", \"moon\", \"science\", \"math\", \"atom\", \"stars\",\n",
      "            \"\\d+[/*^+-]\\d+\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor = util.FeatureExtractor()\n",
      "extractor.add_extractor(worder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#classifier = nltk.classify.NaiveBayesClassifier\n",
      "classifier = nltk.classify.DecisionTreeClassifier\n",
      "#classifier = nltk.classify.SklearnClassifier(LogisticRegression())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor.test(sample_sets, confusion=True, folds=10, classifier=classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "**************************\n",
        "Run 0\n",
        "**************************\n",
        "test 0 - 57.621%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      6      5      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <25.7%>  1.5%      .   2.2%   0.7%   0.4%      . |\n",
        "2 |   5.2%  <7.8%>  0.4%   0.4%   0.4%   0.7%      . |\n",
        "3 |   6.3%   0.4%  <6.3%>  1.9%      .      .      . |\n",
        "4 |   2.2%      .      .  <9.7%>     .      .      . |\n",
        "6 |   5.2%   0.4%      .   1.1%  <4.1%>  0.4%      . |\n",
        "5 |   4.8%      .   0.4%      .   0.7%  <2.6%>  0.4% |\n",
        "7 |   4.8%   0.7%   0.4%      .   0.4%      .  <1.5%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n",
        "\n",
        "test 1 - 58.364%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      6      7      5 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <23.4%>  0.7%   1.5%   1.9%   0.4%      .   0.7% |\n",
        "2 |   7.4%  <7.8%>  1.1%   0.4%      .      .      . |\n",
        "3 |   5.9%      .  <9.3%>  0.7%      .   0.4%      . |\n",
        "4 |   1.5%      .      .  <9.3%>  0.4%   0.4%      . |\n",
        "6 |   5.2%   0.4%      .   0.4%  <3.3%>     .      . |\n",
        "7 |   6.7%      .   0.4%      .      .  <1.9%>  0.4% |\n",
        "5 |   4.5%   0.4%      .      .      .      .  <3.3%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n",
        "\n",
        "test 2 - 56.134%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      5      6      7 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <23.4%>  4.1%      .   0.7%   1.1%   0.7%      . |\n",
        "2 |   8.2%  <9.3%>  0.7%      .   0.4%   0.4%      . |\n",
        "3 |   6.3%   0.7%  <6.7%>  0.7%      .      .      . |\n",
        "4 |   3.0%   0.4%      .  <8.2%>     .      .      . |\n",
        "5 |   4.8%      .   0.4%   0.4%  <3.3%>     .   0.4% |\n",
        "6 |   3.7%      .      .      .      .  <4.8%>     . |\n",
        "7 |   5.2%      .   0.7%      .   0.4%   0.4%  <0.4%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n",
        "\n",
        "test 3 - 55.019%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      2      3      4      7      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <21.9%>  1.1%   1.9%   1.9%      .      .   0.4% |\n",
        "2 |   6.3%  <8.9%>  0.4%      .      .      .      . |\n",
        "3 |   7.8%   0.4%  <6.3%>  1.1%      .      .      . |\n",
        "4 |   3.0%      .   0.4%  <9.3%>     .      .   0.4% |\n",
        "7 |   8.2%   0.4%      .      .  <1.9%>     .      . |\n",
        "5 |   5.9%   0.4%      .      .      .  <3.3%>     . |\n",
        "6 |   4.1%      .      .   1.1%      .      .  <3.3%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n",
        "\n",
        "test 4 - 53.903%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      3      2      4      7      5      6 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <20.1%>  2.2%   1.9%   0.7%      .   0.7%      . |\n",
        "3 |   9.3%  <7.8%>  0.4%   0.4%      .      .   0.4% |\n",
        "2 |   5.9%   0.4%  <9.3%>  0.4%      .   0.4%      . |\n",
        "4 |   3.0%   0.4%      .  <8.6%>     .      .      . |\n",
        "7 |   7.8%   0.4%   0.4%      .  <2.2%>     .   0.4% |\n",
        "5 |   6.7%      .   0.7%      .      .  <2.2%>  0.4% |\n",
        "6 |   2.2%      .      .   0.7%      .      .  <3.7%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n",
        "\n",
        "test 5 - 52.788%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  |      1      3      2      4      7      6      5 |\n",
        "--+--------------------------------------------------+\n",
        "1 | <19.3%>  1.5%   1.5%   3.0%      .   0.4%   0.7% |\n",
        "3 |   6.3% <10.0%>  0.7%   0.7%      .      .   0.4% |\n",
        "2 |   6.3%      .  <8.6%>     .   1.1%   0.4%      . |\n",
        "4 |   5.2%      .   0.7%  <7.8%>     .      .      . |\n",
        "7 |   7.8%   0.4%   0.4%      .  <0.7%>     .      . |\n",
        "6 |   3.7%      .   0.4%   0.7%      .  <3.3%>     . |\n",
        "5 |   4.1%      .   0.4%      .   0.4%      .  <3.0%>|\n",
        "--+--------------------------------------------------+\n",
        "(row = reference; col = test)\n",
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-12-f9538119c54c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, samples, folds, classifier, num_tests, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Run {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"**************************\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mfold_test_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mfold_test_extractor\u001b[1;34m(feature_extractor, samples, folds, classifier, confusion, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mcl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mcl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mget_classifier\u001b[1;34m(self, samples, classifier, retrain)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mretrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_extractors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmake_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/Programming/MIMS/nlp2014_kaggle/testing_util.pyc\u001b[0m in \u001b[0;36mmake_classifier\u001b[1;34m(feature_extractor, train, classifier)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mtrain_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mcl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[1;32m--> 159\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             tree = DecisionTreeClassifier.best_stump(\n\u001b[1;32m--> 152\u001b[1;33m                 feature_names, labeled_featuresets, verbose)\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             tree = DecisionTreeClassifier.best_binary_stump(\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mbest_stump\u001b[1;34m(feature_names, labeled_featuresets, verbose)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mstump\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mstump_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstump\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstump_error\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mbest_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstump_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, labeled_featuresets)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/paul/anaconda/envs/nlp/lib/python2.7/site-packages/nltk/classify/decisiontree.pyc\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(self, featureset)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# Decision tree:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mfval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mfval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decisions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decisions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors = extractor.show_errors(sample_sets, classifier=classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = util.make_classifier(extractor, sample_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_features = util.make_feature(extractor, final_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.show_most_informative_features(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "               has(love) = 1                   4 : 2      =     35.8 : 1.0\n",
        "               has(pain) = 1                   6 : 1      =     34.1 : 1.0\n",
        "                has(sex) = 1                   4 : 2      =     33.5 : 1.0\n",
        "              has(music) = 1                   3 : 1      =     30.9 : 1.0\n",
        "               has(girl) = 1                   4 : 7      =     28.6 : 1.0\n",
        "               has(song) = 1                   3 : 1      =     26.8 : 1.0\n",
        "       has(relationship) = 1                   4 : 1      =     25.2 : 1.0\n",
        "              has(movie) = 1                   3 : 4      =     22.5 : 1.0\n",
        "            has(college) = 1                   5 : 2      =     20.4 : 1.0\n",
        "            has( friend) = 1                   4 : 5      =     20.0 : 1.0\n",
        "                has(boy) = 1                   4 : 5      =     19.5 : 1.0\n",
        "              has(medic) = 1                   6 : 1      =     19.1 : 1.0\n",
        "   has((boy|girl)friend) = 1                   4 : 6      =     19.0 : 1.0\n",
        "           has(internet) = 1                   2 : 3      =     18.8 : 1.0\n",
        "               has(rock) = 1                   3 : 1      =     18.3 : 1.0\n",
        "              has(study) = 1                   5 : 1      =     17.8 : 1.0\n",
        "            has(program) = 1                   2 : 3      =     17.0 : 1.0\n",
        "              has(marri) = 1                   4 : 1      =     16.7 : 1.0\n",
        "           has(software) = 1                   2 : 1      =     16.6 : 1.0\n",
        "              has(blood) = 1                   6 : 1      =     16.5 : 1.0\n",
        "             has(school) = 1                   5 : 2      =     16.0 : 1.0\n",
        "                has(web) = 1                   2 : 6      =     15.9 : 1.0\n",
        "               has(cold) = 1                   6 : 3      =     15.7 : 1.0\n",
        "               has(math) = 1                   7 : 1      =     15.6 : 1.0\n",
        "       has(smok(es|ing)) = 1                   6 : 1      =     14.3 : 1.0\n",
        "              has(grade) = 1                   5 : 1      =     13.6 : 1.0\n",
        "               has(moon) = 1                   7 : 1      =     13.5 : 1.0\n",
        "            has(windows) = 1                   2 : 5      =     12.8 : 1.0\n",
        "            has(episode) = 1                   3 : 1      =     12.0 : 1.0\n",
        "           has(magazine) = 1                   3 : 1      =     12.0 : 1.0\n",
        "            has(english) = 1                   5 : 2      =     11.8 : 1.0\n",
        "              has(teach) = 1                   5 : 2      =     11.8 : 1.0\n",
        "            has(science) = 1                   7 : 1      =     11.4 : 1.0\n",
        "             has(weight) = 1                   6 : 1      =     11.2 : 1.0\n",
        "           has(wireless) = 1                   2 : 1      =     10.7 : 1.0\n",
        "              has(women) = 1                   4 : 5      =     10.6 : 1.0\n",
        "               has(wife) = 1                   4 : 1      =     10.2 : 1.0\n",
        "             has(health) = 1                   6 : 1      =      9.9 : 1.0\n",
        "              has(earth) = 1                   7 : 4      =      9.9 : 1.0\n",
        "             has(riddle) = 1                   3 : 1      =      9.5 : 1.0\n",
        "            has(spanish) = 1                   5 : 1      =      9.4 : 1.0\n",
        "               has(show) = 1                   3 : 6      =      9.4 : 1.0\n",
        "               has(date) = 1                   4 : 3      =      9.1 : 1.0\n",
        "            has(e-?mail) = 1                   2 : 3      =      8.8 : 1.0\n",
        "           has(download) = 1                   2 : 1      =      8.5 : 1.0\n",
        "               has(cure) = 1                   6 : 2      =      8.5 : 1.0\n",
        "              has(point) = 1                   7 : 3      =      8.2 : 1.0\n",
        "             has(educat) = 1                   5 : 1      =      8.2 : 1.0\n",
        "           has(favorite) = 1                   3 : 1      =      8.1 : 1.0\n",
        "               has(comp) = 1                   2 : 4      =      7.6 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = util.make_submission(cl, final_features, writeto=\"submission16ANH.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}